const EXAM_DATA = [
  {"topic":"Topic 1","number":1,"question":"A company makes forecasts each quarter to decide how to optimize operations to meet expected demand. The company uses ML models to make these forecasts. An AI practitioner is writing a report about the trained ML models to provide transparency and explainability to company stakeholders. What should the AI practitioner include in the report to meet the transparency and explainability requirements?","options":{"A":"Code for model training","B":"Partial dependence plots (PDPs)","C":"Sample data for training","D":"Model convergence tables"},"correct_answer":"B"},
  {"topic":"Topic 1","number":2,"question":"A law firm wants to build an AI application by using large language models (LLMs). The application will read legal documents and extract key points from the documents. Which solution meets these requirements?","options":{"A":"Build an automatic named entity recognition system.","B":"Create a recommendation engine.","C":"Develop a summarization chatbot.","D":"Develop a multi-language translation system."},"correct_answer":"C"},
  {"topic":"Topic 1","number":3,"question":"A company wants to classify human genes into 20 categories based on gene characteristics. The company needs an ML algorithm to document how the inner mechanism of the model affects the output. Which ML algorithm meets these requirements?","options":{"A":"Decision trees","B":"Linear regression","C":"Logistic regression","D":"Neural networks"},"correct_answer":"A"},
  {"topic":"Topic 1","number":4,"question":"A company has built an image classification model to predict plant diseases from photos of plant leaves. The company wants to evaluate how many images the model classified correctly. Which evaluation metric should the company use to measure the model's performance?","options":{"A":"R-squared score","B":"Accuracy","C":"Root mean squared error (RMSE)","D":"Learning rate"},"correct_answer":"B"},
  {"topic":"Topic 1","number":5,"question":"A company is using a pre-trained large language model (LLM) to build a chatbot for product recommendations. The company needs the LLM outputs to be short and written in a specific language. Which solution will align the LLM response quality with the company's expectations?","options":{"A":"Adjust the prompt.","B":"Choose an LLM of a different size.","C":"Increase the temperature.","D":"Increase the Top K value."},"correct_answer":"A"},
  {"topic":"Topic 1","number":6,"question":"A company uses Amazon SageMaker for its ML pipeline in a production environment. The company has large input data sizes up to 1 GB and processing times up to 1 hour. The company needs near real-time latency. Which SageMaker inference option meets these requirements?","options":{"A":"Real-time inference","B":"Serverless inference","C":"Asynchronous inference","D":"Batch transform"},"correct_answer":"C"},
  {"topic":"Topic 1","number":7,"question":"A company is using domain-specific models. The company wants to avoid creating new models from the beginning. The company instead wants to adapt pre-trained models to create models for new, related tasks. Which ML strategy meets these requirements?","options":{"A":"Increase the number of epochs.","B":"Use transfer learning.","C":"Decrease the number of epochs.","D":"Use unsupervised learning."},"correct_answer":"B"},
  {"topic":"Topic 1","number":8,"question":"A company is building a solution to generate images for protective eyewear. The solution must have high accuracy and must minimize the risk of incorrect annotations. Which solution will meet these requirements?","options":{"A":"Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus","B":"Data augmentation by using an Amazon Bedrock knowledge base","C":"Image recognition by using Amazon Rekognition","D":"Data summarization by using Amazon QuickSight Q"},"correct_answer":"A"},
  {"topic":"Topic 1","number":9,"question":"A company wants to create a chatbot by using a foundation model (FM) on Amazon Bedrock. The FM needs to access encrypted data that is stored in an Amazon S3 bucket. The data is encrypted with Amazon S3 managed keys (SSE-S3). The FM encounters a failure when attempting to access the S3 bucket data. Which solution will meet these requirements?","options":{"A":"Ensure that the role that Amazon Bedrock assumes has permission to decrypt data with the correct encryption key.","B":"Set the access permissions for the S3 buckets to allow public access to enable access over the internet.","C":"Use prompt engineering techniques to tell the model to look for information in Amazon S3.","D":"Ensure that the S3 data does not contain sensitive information."},"correct_answer":"A"},
  {"topic":"Topic 1","number":10,"question":"A company wants to use language models to create an application for inference on edge devices. The inference must have the lowest latency possible. Which solution will meet these requirements?","options":{"A":"Deploy optimized small language models (SLMs) on edge devices.","B":"Deploy optimized large language models (LLMs) on edge devices.","C":"Incorporate a centralized small language model (SLM) API for asynchronous communication with edge devices.","D":"Incorporate a centralized large language model (LLM) API for asynchronous communication with edge devices."},"correct_answer":"A"},
  {"topic":"Topic 1","number":11,"question":"A company wants to build an ML model by using Amazon SageMaker. The company needs to share and manage variables for model development across multiple teams. Which SageMaker feature meets these requirements?","options":{"A":"Amazon SageMaker Feature Store","B":"Amazon SageMaker Data Wrangler","C":"Amazon SageMaker Clarify","D":"Amazon SageMaker Model Cards"},"correct_answer":"A"},
  {"topic":"Topic 1","number":12,"question":"A company wants to use generative AI to increase developer productivity and software development. The company wants to use Amazon Q Developer. What can Amazon Q Developer do to help the company meet these requirements?","options":{"A":"Create software snippets, reference tracking, and open source license tracking.","B":"Run an application without provisioning or managing servers.","C":"Enable voice commands for coding and providing natural language search.","D":"Convert audio files to text documents by using ML models."},"correct_answer":"A"},
  {"topic":"Topic 1","number":13,"question":"A financial institution is using Amazon Bedrock to develop an AI application. The application is hosted in a VPC. To meet regulatory compliance standards, the VPC is not allowed access to any internet traffic. Which AWS service or feature will meet these requirements?","options":{"A":"AWS PrivateLink","B":"Amazon Macie","C":"Amazon CloudFront","D":"Internet gateway"},"correct_answer":"A"},
  {"topic":"Topic 1","number":14,"question":"A company wants to develop an educational game where users answer questions such as the following: \"A jar contains six red, four green, and three yellow marbles. What is the probability of choosing a green marble from the jar?\" Which solution meets these requirements with the LEAST operational overhead?","options":{"A":"Use supervised learning to create a regression model that will predict probability.","B":"Use reinforcement learning to train a model to return the probability.","C":"Use code that will calculate probability by using simple rules and computations.","D":"Use unsupervised learning to create a model that will estimate probability density."},"correct_answer":"C"},
  {"topic":"Topic 1","number":15,"question":"Which metric measures the runtime efficiency of operating AI models?","options":{"A":"Customer satisfaction score (CSAT)","B":"Training time for each epoch","C":"Average response time","D":"Number of training instances"},"correct_answer":"C"},
  {"topic":"Topic 1","number":16,"question":"A company is building a contact center application and wants to gain insights from customer conversations. The company wants to analyze and extract key information from the audio of the customer calls. Which solution meets these requirements?","options":{"A":"Build a conversational chatbot by using Amazon Lex.","B":"Transcribe call recordings by using Amazon Transcribe.","C":"Extract information from call recordings by using Amazon SageMaker Model Monitor.","D":"Create classification labels by using Amazon Comprehend."},"correct_answer":"B"},
  {"topic":"Topic 1","number":17,"question":"A company has petabytes of unlabeled customer data to use for an advertisement campaign. The company wants to classify its customers into tiers to advertise and promote the company's products. Which methodology should the company use to meet these requirements?","options":{"A":"Supervised learning","B":"Unsupervised learning","C":"Reinforcement learning","D":"Reinforcement learning from human feedback (RLHF)"},"correct_answer":"B"},
  {"topic":"Topic 1","number":18,"question":"An AI practitioner wants to use a foundation model (FM) to design a search application. The search application must handle queries that have text and images. Which type of FM should the AI practitioner use to power the search application?","options":{"A":"Multi-modal embedding model","B":"Text embedding model","C":"Multi-modal generation model","D":"Image generation model"},"correct_answer":"A"},
  {"topic":"Topic 1","number":19,"question":"A company uses a foundation model (FM) from Amazon Bedrock for an AI search tool. The company wants to fine-tune the model to be more accurate by using the company's data. Which strategy will successfully fine-tune the model?","options":{"A":"Provide labeled data with the prompt field and the completion field.","B":"Prepare the training dataset by creating a .txt file that contains multiple lines in .csv format.","C":"Purchase Provisioned Throughput for Amazon Bedrock.","D":"Train the model on journals and textbooks."},"correct_answer":"A"},
  {"topic":"Topic 1","number":20,"question":"A company wants to use AI to protect its application from threats. The AI solution needs to check if an IP address is from a suspicious source. Which solution meets these requirements?","options":{"A":"Build a speech recognition system.","B":"Create a natural language processing (NLP) named entity recognition system.","C":"Develop an anomaly detection system.","D":"Create a fraud forecasting system."},"correct_answer":"C"},
  {"topic":"Topic 1","number":21,"question":"Which feature of Amazon OpenSearch Service gives companies the ability to build vector database applications?","options":{"A":"Integration with Amazon S3 for object storage","B":"Support for geospatial indexing and queries","C":"Scalable index management and nearest neighbor search capability","D":"Ability to perform real-time analysis on streaming data"},"correct_answer":"C"},
  {"topic":"Topic 1","number":22,"question":"Which option is a use case for generative AI models?","options":{"A":"Improving network security by using intrusion detection systems","B":"Creating photorealistic images from text descriptions for digital marketing","C":"Enhancing database performance by using optimized indexing","D":"Analyzing financial data to forecast stock market trends"},"correct_answer":"B"},
  {"topic":"Topic 1","number":23,"question":"A company wants to build a generative AI application by using Amazon Bedrock and needs to choose a foundation model (FM). The company wants to know how much information can fit into one prompt. Which consideration will inform the company's decision?","options":{"A":"Temperature","B":"Context window","C":"Batch size","D":"Model size"},"correct_answer":"B"},
  {"topic":"Topic 1","number":24,"question":"A company wants to make a chatbot to help customers. The chatbot will help solve technical problems without human intervention. The company chose a foundation model (FM) for the chatbot. The chatbot needs to produce responses that adhere to company tone. Which solution meets these requirements?","options":{"A":"Set a low limit on the number of tokens the FM can produce.","B":"Use batch inferencing to process detailed responses.","C":"Experiment and refine the prompt until the FM produces the desired responses.","D":"Define a higher number for the temperature parameter."},"correct_answer":"C"},
  {"topic":"Topic 1","number":25,"question":"A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company wants to classify the sentiment of text passages as positive or negative. Which prompt engineering strategy meets these requirements?","options":{"A":"Provide examples of text passages with corresponding positive or negative labels in the prompt followed by the new text passage to be classified.","B":"Provide a detailed explanation of sentiment analysis and how LLMs work in the prompt.","C":"Provide the new text passage to be classified without any additional context or examples.","D":"Provide the new text passage with a few examples of unrelated tasks, such as text summarization or question answering."},"correct_answer":"A"},
  {"topic":"Topic 1","number":26,"question":"A security company is using Amazon Bedrock to run foundation models (FMs). The company wants to ensure that only authorized users invoke the models. The company needs to identify any unauthorized access attempts to set appropriate AWS Identity and Access Management (IAM) policies and roles for future iterations of the FMs. Which AWS service should the company use to identify unauthorized users that are trying to access Amazon Bedrock?","options":{"A":"AWS Audit Manager","B":"AWS CloudTrail","C":"Amazon Fraud Detector","D":"AWS Trusted Advisor"},"correct_answer":"B"},
  {"topic":"Topic 1","number":27,"question":"A company has developed an ML model for image classification. The company wants to deploy the model to production so that a web application can use the model. The company needs to implement a solution to host the model and serve predictions without managing any of the underlying infrastructure. Which solution will meet these requirements?","options":{"A":"Use Amazon SageMaker Serverless Inference to deploy the model.","B":"Use Amazon CloudFront to deploy the model.","C":"Use Amazon API Gateway to host the model and serve predictions.","D":"Use AWS Batch to host the model and serve predictions."},"correct_answer":"A"},
  {"topic":"Topic 1","number":28,"question":"An AI company periodically evaluates its systems and processes with the help of independent software vendors (ISVs). The company needs to receive email message notifications when an ISV's compliance reports become available. Which AWS service can the company use to meet this requirement?","options":{"A":"AWS Audit Manager","B":"AWS Artifact","C":"AWS Trusted Advisor","D":"AWS Data Exchange"},"correct_answer":"B"},
  {"topic":"Topic 1","number":29,"question":"A company wants to use a large language model (LLM) to develop a conversational agent. The company needs to prevent the LLM from being manipulated with common prompt engineering techniques to perform undesirable actions or expose sensitive information. Which action will reduce these risks?","options":{"A":"Create a prompt template that teaches the LLM to detect attack patterns.","B":"Increase the temperature parameter on invocation requests to the LLM.","C":"Avoid using LLMs that are not listed in Amazon SageMaker.","D":"Decrease the number of input tokens on invocations of the LLM."},"correct_answer":"A"},
  {"topic":"Topic 1","number":30,"question":"A company is using the Generative AI Security Scoping Matrix to assess security responsibilities for its solutions. The company has identified four different solution scopes based on the matrix. Which solution scope gives the company the MOST ownership of security responsibilities?","options":{"A":"Using a third-party enterprise application that has embedded generative AI features.","B":"Building an application by using an existing third-party generative AI foundation model (FM).","C":"Refining an existing third-party generative AI foundation model (FM) by fine-tuning the model by using data specific to the business.","D":"Building and training a generative AI model from scratch by using specific data that a customer owns."},"correct_answer":"D"},
  {"topic":"Topic 1","number":31,"question":"An AI practitioner has a database of animal photos. The AI practitioner wants to automatically identify and categorize the animals in the photos without manual human effort. Which strategy meets these requirements?","options":{"A":"Object detection","B":"Anomaly detection","C":"Named entity recognition","D":"Inpainting"},"correct_answer":"A"},
  {"topic":"Topic 1","number":32,"question":"A company wants to create an application by using Amazon Bedrock. The company has a limited budget and prefers flexibility without long-term commitment. Which Amazon Bedrock pricing model meets these requirements?","options":{"A":"On-Demand","B":"Model customization","C":"Provisioned Throughput","D":"Spot Instance"},"correct_answer":"A"},
  {"topic":"Topic 1","number":33,"question":"Which AWS service or feature can help an AI development team quickly deploy and consume a foundation model (FM) within the team's VPC?","options":{"A":"Amazon Personalize","B":"Amazon SageMaker JumpStart","C":"PartyRock, an Amazon Bedrock Playground","D":"Amazon SageMaker endpoints"},"correct_answer":"B"},
  {"topic":"Topic 1","number":34,"question":"How can companies use large language models (LLMs) securely on Amazon Bedrock?","options":{"A":"Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.","B":"Enable AWS Audit Manager for automatic model evaluation jobs.","C":"Enable Amazon Bedrock automatic model evaluation jobs.","D":"Use Amazon CloudWatch Logs to make models explainable and to monitor for bias."},"correct_answer":"A"},
  {"topic":"Topic 1","number":35,"question":"A company has terabytes of data in a database that the company can use for business analysis. The company wants to build an AI-based application that can build a SQL query from input text that employees provide. The employees have minimal experience with technology. Which solution meets these requirements?","options":{"A":"Generative pre-trained transformers (GPT)","B":"Residual neural network","C":"Support vector machine","D":"WaveNet"},"correct_answer":"A"},
  {"topic":"Topic 1","number":36,"question":"A company built a deep learning model for object detection and deployed the model to production. Which AI process occurs when the model analyzes a new image to identify objects?","options":{"A":"Training","B":"Inference","C":"Model deployment","D":"Bias correction"},"correct_answer":"B"},
  {"topic":"Topic 1","number":37,"question":"An AI practitioner is building a model to generate images of humans in various professions. The AI practitioner discovered that the input data is biased and that specific attributes affect the image generation and create bias in the model. Which technique will solve the problem?","options":{"A":"Data augmentation for imbalanced classes","B":"Model monitoring for class distribution","C":"Retrieval Augmented Generation (RAG)","D":"Watermark detection for images"},"correct_answer":"A"},
  {"topic":"Topic 1","number":38,"question":"A company is implementing the Amazon Titan foundation model (FM) by using Amazon Bedrock. The company needs to supplement the model by using relevant data from the company's private data sources. Which solution will meet this requirement?","options":{"A":"Use a different FM.","B":"Choose a lower temperature value.","C":"Create an Amazon Bedrock knowledge base.","D":"Enable model invocation logging."},"correct_answer":"C"},
  {"topic":"Topic 1","number":39,"question":"A medical company is customizing a foundation model (FM) for diagnostic purposes. The company needs the model to be transparent and explainable to meet regulatory requirements. Which solution will meet these requirements?","options":{"A":"Configure the security and compliance by using Amazon Inspector.","B":"Generate simple metrics, reports, and examples by using Amazon SageMaker Clarify.","C":"Encrypt and secure training data by using Amazon Macie.","D":"Gather more data. Use Amazon Rekognition to add custom labels to the data."},"correct_answer":"B"},
  {"topic":"Topic 1","number":40,"question":"A company wants to deploy a conversational chatbot to answer customer questions. The chatbot is based on a fine-tuned Amazon SageMaker JumpStart model. The application must comply with multiple regulatory frameworks. Which capabilities can the company show compliance for? (Choose two.)","options":{"A":"Auto scaling inference endpoints","B":"Threat detection","C":"Data protection","D":"Cost optimization","E":"Loosely coupled microservices"},"correct_answer":["B","C"]},
  {"topic":"Topic 1","number":41,"question":"A company is training a foundation model (FM). The company wants to increase the accuracy of the model up to a specific acceptance level. Which solution will meet these requirements?","options":{"A":"Decrease the batch size.","B":"Increase the epochs.","C":"Decrease the epochs.","D":"Increase the temperature parameter."},"correct_answer":"B"},
  {"topic":"Topic 1","number":42,"question":"A company is building a large language model (LLM) question answering chatbot. The company wants to decrease the number of actions call center employees need to take to respond to customer questions. Which business objective should the company use to evaluate the effect of the LLM chatbot?","options":{"A":"Website engagement rate","B":"Average call duration","C":"Corporate social responsibility","D":"Regulatory compliance"},"correct_answer":"B"},
  {"topic":"Topic 1","number":43,"question":"Which functionality does Amazon SageMaker Clarify provide?","options":{"A":"Integrates a Retrieval Augmented Generation (RAG) workflow","B":"Monitors the quality of ML models in production","C":"Documents critical details about ML models","D":"Identifies potential bias during data preparation"},"correct_answer":"D"},
  {"topic":"Topic 1","number":44,"question":"A company is developing a new model to predict the prices of specific items. The model performed well on the training dataset. When the company deployed the model to production, the model's performance decreased significantly. What should the company do to mitigate this problem?","options":{"A":"Reduce the volume of data that is used in training.","B":"Add hyperparameters to the model.","C":"Increase the volume of data that is used in training.","D":"Increase the model training time."},"correct_answer":"C"},
  {"topic":"Topic 1","number":45,"question":"An ecommerce company wants to build a solution to determine customer sentiments based on written customer reviews of products. Which AWS services meet these requirements? (Choose two.)","options":{"A":"Amazon Lex","B":"Amazon Comprehend","C":"Amazon Polly","D":"Amazon Bedrock","E":"Amazon Rekognition"},"correct_answer":["B","D"]},
  {"topic":"Topic 1","number":46,"question":"A company wants to use large language models (LLMs) with Amazon Bedrock to develop a chat interface for the company's product manuals. The manuals are stored as PDF files. Which solution meets these requirements MOST cost-effectively?","options":{"A":"Use prompt engineering to add one PDF file as context to the user prompt when the prompt is submitted to Amazon Bedrock.","B":"Use prompt engineering to add all the PDF files as context to the user prompt when the prompt is submitted to Amazon Bedrock.","C":"Use all the PDF documents to fine-tune a model with Amazon Bedrock. Use the fine-tuned model to process user prompts.","D":"Upload PDF documents to an Amazon Bedrock knowledge base. Use the knowledge base to provide context when users submit prompts to Amazon Bedrock."},"correct_answer":"D"},
  {"topic":"Topic 1","number":47,"question":"A social media company wants to use a large language model (LLM) for content moderation. The company wants to evaluate the LLM outputs for bias and potential discrimination against specific groups or individuals. Which data source should the company use to evaluate the LLM outputs with the LEAST administrative effort?","options":{"A":"User-generated content","B":"Moderation logs","C":"Content moderation guidelines","D":"Benchmark datasets"},"correct_answer":"D"},
  {"topic":"Topic 1","number":48,"question":"A company wants to use a pre-trained generative AI model to generate content for its marketing campaigns. The company needs to ensure that the generated content aligns with the company's brand voice and messaging requirements. Which solution meets these requirements?","options":{"A":"Optimize the model's architecture and hyperparameters to improve the model's overall performance.","B":"Increase the model's complexity by adding more layers to the model's architecture.","C":"Create effective prompts that provide clear instructions and context to guide the model's generation.","D":"Select a large, diverse dataset to pre-train a new generative model."},"correct_answer":"C"},
  {"topic":"Topic 1","number":49,"question":"A loan company is building a generative AI-based solution to offer new applicants discounts based on specific business criteria. The company wants to build and use an AI model responsibly to minimize bias that could negatively affect some customers. Which actions should the company take to meet these requirements? (Choose two.)","options":{"A":"Detect imbalances or disparities in the data.","B":"Ensure that the model runs frequently.","C":"Evaluate the model's behavior so that the company can provide transparency to stakeholders.","D":"Use the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) technique to ensure that the model is 100% accurate.","E":"Ensure that the model's inference time is within the accepted limits."},"correct_answer":["A","C"]},
  {"topic":"Topic 1","number":50,"question":"A company is using an Amazon Bedrock base model to summarize documents for an internal use case. The company trained a custom model to improve the summarization quality. Which action must the company take to use the custom model through Amazon Bedrock?","options":{"A":"Purchase Provisioned Throughput for the custom model.","B":"Deploy the custom model in an Amazon SageMaker endpoint for real-time inference.","C":"Register the model with the Amazon SageMaker Model Registry.","D":"Grant access to the custom model in Amazon Bedrock."},"correct_answer":"A"},
  {"topic":"Topic 1","number":51,"question":"A company needs to choose a model from Amazon Bedrock to use internally. The company must identify a model that generates responses in a style that the company's employees prefer. What should the company do to meet these requirements?","options":{"A":"Evaluate the models by using built-in prompt datasets.","B":"Evaluate the models by using a human workforce and custom prompt datasets.","C":"Use public model leaderboards to identify the model.","D":"Use the model InvocationLatency runtime metrics in Amazon CloudWatch when trying models."},"correct_answer":"B"},
  {"topic":"Topic 1","number":52,"question":"A student at a university is copying content from generative AI to write essays. Which challenge of responsible generative AI does this scenario represent?","options":{"A":"Toxicity","B":"Hallucinations","C":"Plagiarism","D":"Privacy"},"correct_answer":"C"},
  {"topic":"Topic 1","number":53,"question":"A company needs to build its own large language model (LLM) based on only the company's private data. The company is concerned about the environmental effect of the training process. Which Amazon EC2 instance type has the LEAST environmental effect when training LLMs?","options":{"A":"Amazon EC2 C series","B":"Amazon EC2 G series","C":"Amazon EC2 P series","D":"Amazon EC2 Trn series"},"correct_answer":"D"},
  {"topic":"Topic 1","number":54,"question":"A company wants to build an interactive application for children that generates new stories based on classic stories. The company wants to use Amazon Bedrock and needs to ensure that the results and topics are appropriate for children. Which AWS service or feature will meet these requirements?","options":{"A":"Amazon Rekognition","B":"Amazon Bedrock playgrounds","C":"Guardrails for Amazon Bedrock","D":"Agents for Amazon Bedrock"},"correct_answer":"C"},
  {"topic":"Topic 1","number":55,"question":"A company is building an application that needs to generate synthetic data that is based on existing data. Which type of model can the company use to meet this requirement?","options":{"A":"Generative adversarial network (GAN)","B":"XGBoost","C":"Residual neural network","D":"WaveNet"},"correct_answer":"A"},
  {"topic":"Topic 1","number":56,"question":"A digital devices company wants to predict customer demand for memory hardware. The company does not have coding experience or knowledge of ML algorithms and needs to develop a data-driven predictive model. The company needs to perform analysis on internal data and external data. Which solution will meet these requirements?","options":{"A":"Store the data in Amazon S3. Create ML models and demand forecast predictions by using Amazon SageMaker built-in algorithms that use the data from Amazon S3.","B":"Import the data into Amazon SageMaker Data Wrangler. Create ML models and demand forecast predictions by using SageMaker built-in algorithms.","C":"Import the data into Amazon SageMaker Data Wrangler. Build ML models and demand forecast predictions by using an Amazon Personalize Trending-Now recipe.","D":"Import the data into Amazon SageMaker Canvas. Build ML models and demand forecast predictions by selecting the values in the data from SageMaker Canvas."},"correct_answer":"D"},
  {"topic":"Topic 1","number":57,"question":"A company has installed a security camera. The company uses an ML model to evaluate the security camera footage for potential thefts. The company has discovered that the model disproportionately flags people who are members of a specific ethnic group. Which type of bias is affecting the model output?","options":{"A":"Measurement bias","B":"Sampling bias","C":"Observer bias","D":"Confirmation bias"},"correct_answer":"B"},
  {"topic":"Topic 1","number":58,"question":"A company is building a customer service chatbot. The company wants the chatbot to improve its responses by learning from past interactions and online resources. Which AI learning strategy provides this self-improvement capability?","options":{"A":"Supervised learning with a manually curated dataset of good responses and bad responses","B":"Reinforcement learning with rewards for positive customer feedback","C":"Unsupervised learning to find clusters of similar customer inquiries","D":"Supervised learning with a continuously updated FAQ database"},"correct_answer":"B"},
  {"topic":"Topic 1","number":59,"question":"An AI practitioner has built a deep learning model to classify the types of materials in images. The AI practitioner now wants to measure the model performance. Which metric will help the AI practitioner evaluate the performance of the model?","options":{"A":"Confusion matrix","B":"Correlation matrix","C":"R2 score","D":"Mean squared error (MSE)"},"correct_answer":"A"},
  {"topic":"Topic 1","number":60,"question":"A company has built a chatbot that can respond to natural language questions with images. The company wants to ensure that the chatbot does not return inappropriate or unwanted images. Which solution will meet these requirements?","options":{"A":"Implement moderation APIs.","B":"Retrain the model with a general public dataset.","C":"Perform model validation.","D":"Automate user feedback integration."},"correct_answer":"A"},
  {"topic":"Topic 1","number":61,"question":"An AI practitioner is using an Amazon Bedrock base model to summarize session chats from the customer service department. The AI practitioner wants to store invocation logs to monitor model input and output data. Which strategy should the AI practitioner use?","options":{"A":"Configure AWS CloudTrail as the logs destination for the model.","B":"Enable invocation logging in Amazon Bedrock.","C":"Configure AWS Audit Manager as the logs destination for the model.","D":"Configure model invocation logging in Amazon EventBridge."},"correct_answer":"B"},
  {"topic":"Topic 1","number":62,"question":"A company is building an ML model to analyze archived data. The company must perform inference on large datasets that are multiple GBs in size. The company does not need to access the model predictions immediately. Which Amazon SageMaker inference option will meet these requirements?","options":{"A":"Batch transform","B":"Real-time inference","C":"Serverless inference","D":"Asynchronous inference"},"correct_answer":"A"},
  {"topic":"Topic 1","number":63,"question":"Which term describes the numerical representations of real-world objects and concepts that AI and natural language processing (NLP) models use to improve understanding of textual information?","options":{"A":"Embeddings","B":"Tokens","C":"Models","D":"Binaries"},"correct_answer":"A"},
  {"topic":"Topic 1","number":64,"question":"A research company implemented a chatbot by using a foundation model (FM) from Amazon Bedrock. The chatbot searches for answers to questions from a large database of research papers. After multiple prompt engineering attempts, the company notices that the FM is performing poorly because of the complex scientific terms in the research papers. How can the company improve the performance of the chatbot?","options":{"A":"Use few-shot prompting to define how the FM can answer the questions.","B":"Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.","C":"Change the FM inference parameters.","D":"Clean the research paper data to remove complex scientific terms."},"correct_answer":"B"},
  {"topic":"Topic 1","number":65,"question":"A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company needs the LLM to produce more consistent responses to the same input prompt. Which adjustment to an inference parameter should the company make to meet these requirements?","options":{"A":"Decrease the temperature value.","B":"Increase the temperature value.","C":"Decrease the length of output tokens.","D":"Increase the maximum generation length."},"correct_answer":"A"},
  {"topic":"Topic 1","number":66,"question":"A company wants to develop a large language model (LLM) application by using Amazon Bedrock and customer data that is uploaded to Amazon S3. The company's security policy states that each team can access data for only the team's own customers. Which solution will meet these requirements?","options":{"A":"Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.","B":"Create a custom service role that has Amazon S3 access. Ask teams to specify the customer name on each Amazon Bedrock request.","C":"Redact personal data in Amazon S3. Update the S3 bucket policy to allow team access to customer data.","D":"Create one Amazon Bedrock role that has full Amazon S3 access. Create IAM roles for each team that have access to only each team's customer folders."},"correct_answer":"A"},
  {"topic":"Topic 1","number":67,"question":"A medical company deployed a disease detection model on Amazon Bedrock. To comply with privacy policies, the company wants to prevent the model from including personal patient information in its responses. The company also wants to receive notification when policy violations occur. Which solution meets these requirements?","options":{"A":"Use Amazon Macie to scan the model's output for sensitive data and set up alerts for potential violations.","B":"Configure AWS CloudTrail to monitor the model's responses and create alerts for any detected personal information.","C":"Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.","D":"Implement Amazon SageMaker Model Monitor to detect data drift and receive alerts when model quality degrades."},"correct_answer":"C"},
  {"topic":"Topic 1","number":68,"question":"A company manually reviews all submitted resumes in PDF format. As the company grows, the company expects the volume of resumes to exceed the company's review capacity. The company needs an automated system to convert the PDF resumes into plain text format for additional processing. Which AWS service meets this requirement?","options":{"A":"Amazon Textract","B":"Amazon Personalize","C":"Amazon Lex","D":"Amazon Transcribe"},"correct_answer":"A"},
  {"topic":"Topic 1","number":69,"question":"An education provider is building a question and answer application that uses a generative AI model to explain complex concepts. The education provider wants to automatically change the style of the model response depending on who is asking the question. The education provider will give the model the age range of the user who has asked the question. Which solution meets these requirements with the LEAST implementation effort?","options":{"A":"Fine-tune the model by using additional training data that is representative of the various age ranges that the application will support.","B":"Add a role description to the prompt context that instructs the model of the age range that the response should target.","C":"Use chain-of-thought reasoning to deduce the correct style and complexity for a response suitable for that user.","D":"Summarize the response text depending on the age of the user so that younger users receive shorter responses."},"correct_answer":"B"},
  {"topic":"Topic 1","number":70,"question":"Which strategy evaluates the accuracy of a foundation model (FM) that is used in image classification tasks?","options":{"A":"Calculate the total cost of resources used by the model.","B":"Measure the model's accuracy against a predefined benchmark dataset.","C":"Count the number of layers in the neural network.","D":"Assess the color accuracy of images processed by the model."},"correct_answer":"B"},
  {"topic":"Topic 1","number":71,"question":"An accounting firm wants to implement a large language model (LLM) to automate document processing. The firm must proceed responsibly to avoid potential harms. What should the firm do when developing and deploying the LLM? (Choose two.)","options":{"A":"Include fairness metrics for model evaluation.","B":"Adjust the temperature parameter of the model.","C":"Modify the training data to mitigate bias.","D":"Avoid overfitting on the training data.","E":"Apply prompt engineering techniques."},"correct_answer":["A","C"]},
  {"topic":"Topic 1","number":72,"question":"A company is building an ML model. The company collected new data and analyzed the data by creating a correlation matrix, calculating statistics, and visualizing the data. Which stage of the ML pipeline is the company currently in?","options":{"A":"Data pre-processing","B":"Feature engineering","C":"Exploratory data analysis","D":"Hyperparameter tuning"},"correct_answer":"C"},
  {"topic":"Topic 1","number":73,"question":"A company has documents that are missing some words because of a database error. The company wants to build an ML model that can suggest potential words to fill in the missing text. Which type of model meets this requirement?","options":{"A":"Topic modeling","B":"Clustering models","C":"Prescriptive ML models","D":"BERT-based models"},"correct_answer":"D"},
  {"topic":"Topic 1","number":74,"question":"A company wants to display the total sales for its top-selling products across various retail locations in the past 12 months. Which AWS solution should the company use to automate the generation of graphs?","options":{"A":"Amazon Q in Amazon EC2","B":"Amazon Q Developer","C":"Amazon Q in Amazon QuickSight","D":"Amazon Q in AWS Chatbot"},"correct_answer":"C"},
  {"topic":"Topic 1","number":75,"question":"A company is building a chatbot to improve user experience. The company is using a large language model (LLM) from Amazon Bedrock for intent detection. The company wants to use few-shot learning to improve intent detection accuracy. Which additional data does the company need to meet these requirements?","options":{"A":"Pairs of chatbot responses and correct user intents","B":"Pairs of user messages and correct chatbot responses","C":"Pairs of user messages and correct user intents","D":"Pairs of user intents and correct chatbot responses"},"correct_answer":"C"},
  {"topic":"Topic 1","number":76,"question":"A company is using few-shot prompting on a base model that is hosted on Amazon Bedrock. The model currently uses 10 examples in the prompt. The model is invoked once daily and is performing well. The company wants to lower the monthly cost. Which solution will meet these requirements?","options":{"A":"Customize the model by using fine-tuning.","B":"Decrease the number of tokens in the prompt.","C":"Increase the number of tokens in the prompt.","D":"Use Provisioned Throughput."},"correct_answer":"B"},
  {"topic":"Topic 1","number":77,"question":"An AI practitioner is using a large language model (LLM) to create content for marketing campaigns. The generated content sounds plausible and factual but is incorrect. Which problem is the LLM having?","options":{"A":"Data leakage","B":"Hallucination","C":"Overfitting","D":"Underfitting"},"correct_answer":"B"},
  {"topic":"Topic 1","number":78,"question":"An AI practitioner trained a custom model on Amazon Bedrock by using a training dataset that contains confidential data. The AI practitioner wants to ensure that the custom model does not generate inference responses based on confidential data. How should the AI practitioner prevent responses based on confidential data?","options":{"A":"Delete the custom model. Remove the confidential data from the training dataset. Retrain the custom model.","B":"Mask the confidential data in the inference responses by using dynamic data masking.","C":"Encrypt the confidential data in the inference responses by using Amazon SageMaker.","D":"Encrypt the confidential data in the custom model by using AWS Key Management Service (AWS KMS)."},"correct_answer":"A"},
  {"topic":"Topic 1","number":79,"question":"A company has built a solution by using generative AI. The solution uses large language models (LLMs) to translate training manuals from English into other languages. The company wants to evaluate the accuracy of the solution by examining the text generated for the manuals. Which model evaluation strategy meets these requirements?","options":{"A":"Bilingual Evaluation Understudy (BLEU)","B":"Root mean squared error (RMSE)","C":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE)","D":"F1 score"},"correct_answer":"A"},
  {"topic":"Topic 1","number":80,"question":"A large retailer receives thousands of customer support inquiries about products every day. The customer support inquiries need to be processed and responded to quickly. The company wants to implement Agents for Amazon Bedrock. What are the key benefits of using Amazon Bedrock agents that could help this retailer?","options":{"A":"Generation of custom foundation models (FMs) to predict customer needs","B":"Automation of repetitive tasks and orchestration of complex workflows","C":"Automatically calling multiple foundation models (FMs) and consolidating the results","D":"Selecting the foundation model (FM) based on predefined criteria and metrics"},"correct_answer":"B"},
  {"topic":"Topic 1","number":81,"question":"Which option is a benefit of ongoing pre-training when fine-tuning a foundation model (FM)?","options":{"A":"Helps decrease the model's complexity","B":"Improves model performance over time","C":"Decreases the training time requirement","D":"Optimizes model inference time"},"correct_answer":"B"},
  {"topic":"Topic 1","number":82,"question":"What are tokens in the context of generative AI models?","options":{"A":"Tokens are the basic units of input and output that a generative AI model operates on, representing words, subwords, or other linguistic units.","B":"Tokens are the mathematical representations of words or concepts used in generative AI models.","C":"Tokens are the pre-trained weights of a generative AI model that are fine-tuned for specific tasks.","D":"Tokens are the specific prompts or instructions given to a generative AI model to generate output."},"correct_answer":"A"},
  {"topic":"Topic 1","number":83,"question":"A company wants to assess the costs that are associated with using a large language model (LLM) to generate inferences. The company wants to use Amazon Bedrock to build generative AI applications. Which factor will drive the inference costs?","options":{"A":"Number of tokens consumed","B":"Temperature value","C":"Amount of data used to train the LLM","D":"Total training time"},"correct_answer":"A"},
  {"topic":"Topic 1","number":84,"question":"A company is using Amazon SageMaker Studio notebooks to build and train ML models. The company stores the data in an Amazon S3 bucket. The company needs to manage the flow of data from Amazon S3 to SageMaker Studio notebooks. Which solution will meet this requirement?","options":{"A":"Use Amazon Inspector to monitor SageMaker Studio.","B":"Use Amazon Macie to monitor SageMaker Studio.","C":"Configure SageMaker to use a VPC with an S3 endpoint.","D":"Configure SageMaker to use S3 Glacier Deep Archive."},"correct_answer":"C"},
  {"topic":"Topic 1","number":85,"question":"A company has a foundation model (FM) that was customized by using Amazon Bedrock to answer customer queries about products. The company wants to validate the model's responses to new types of queries. The company needs to upload a new dataset that Amazon Bedrock can use for validation. Which AWS service meets these requirements?","options":{"A":"Amazon S3","B":"Amazon Elastic Block Store (Amazon EBS)","C":"Amazon Elastic File System (Amazon EFS)","D":"AWS Snowcone"},"correct_answer":"A"},
  {"topic":"Topic 1","number":86,"question":"Which prompting attack directly exposes the configured behavior of a large language model (LLM)?","options":{"A":"Prompted persona switches","B":"Exploiting friendliness and trust","C":"Ignoring the prompt template","D":"Extracting the prompt template"},"correct_answer":"D"},
  {"topic":"Topic 1","number":87,"question":"A company wants to use Amazon Bedrock. The company needs to review which security aspects the company is responsible for when using Amazon Bedrock. Which security aspect will the company be responsible for?","options":{"A":"Patching and updating the versions of Amazon Bedrock","B":"Protecting the infrastructure that hosts Amazon Bedrock","C":"Securing the company's data in transit and at rest","D":"Provisioning Amazon Bedrock within the company network"},"correct_answer":"C"},
  {"topic":"Topic 1","number":88,"question":"A social media company wants to use a large language model (LLM) to summarize messages. The company has chosen a few LLMs that are available on Amazon SageMaker JumpStart. The company wants to compare the generated output toxicity of these models. Which strategy gives the company the ability to evaluate the LLMs with the LEAST operational overhead?","options":{"A":"Crowd-sourced evaluation","B":"Automatic model evaluation","C":"Model evaluation with human workers","D":"Reinforcement learning from human feedback (RLHF)"},"correct_answer":"B"},
  {"topic":"Topic 1","number":89,"question":"A company is testing the security of a foundation model (FM). During testing, the company wants to get around the safety features and make harmful content. Which security technique is this an example of?","options":{"A":"Fuzzing training data to find vulnerabilities","B":"Denial of service (DoS)","C":"Penetration testing with authorization","D":"Jailbreak"},"correct_answer":"D"},
  {"topic":"Topic 1","number":90,"question":"A company needs to use Amazon SageMaker for model training and inference. The company must comply with regulatory requirements to run SageMaker jobs in an isolated environment without internet access. Which solution will meet these requirements?","options":{"A":"Run SageMaker training and inference by using SageMaker Experiments.","B":"Run SageMaker training and Inference by using network Isolation.","C":"Encrypt the data at rest by using encryption for SageMaker geospatial capabilities.","D":"Associate appropriate AWS Identity and Access Management (IAM) roles with the SageMaker jobs."},"correct_answer":"B"},
  {"topic":"Topic 1","number":91,"question":"An ML research team develops custom ML models. The model artifacts are shared with other teams for integration into products and services. The ML team retains the model training code and data. The ML team wants to build a mechanism that the ML team can use to audit models. Which solution should the ML team use when publishing the custom ML models?","options":{"A":"Create documents with the relevant information. Store the documents in Amazon S3.","B":"Use AWS AI Service Cards for transparency and understanding models.","C":"Create Amazon SageMaker Model Cards with intended uses and training and inference details.","D":"Create model training scripts. Commit the model training scripts to a Git repository."},"correct_answer":"C"},
  {"topic":"Topic 1","number":92,"question":"A software company builds tools for customers. The company wants to use AI to increase software development productivity. Which solution will meet these requirements?","options":{"A":"Use a binary classification model to generate code reviews.","B":"Install code recommendation software in the company's developer tools.","C":"Install a code forecasting tool to predict potential code issues.","D":"Use a natural language processing (NLP) tool to generate code."},"correct_answer":"B"},
  {"topic":"Topic 1","number":93,"question":"A retail store wants to predict the demand for a specific product for the next few weeks by using the Amazon SageMaker DeepAR forecasting algorithm. Which type of data will meet this requirement?","options":{"A":"Text data","B":"Image data","C":"Time series data","D":"Binary data"},"correct_answer":"C"},
  {"topic":"Topic 1","number":94,"question":"A large retail bank wants to develop an ML system to help the risk management team decide on loan allocations for different demographics. What must the bank do to develop an unbiased ML model?","options":{"A":"Reduce the size of the training dataset.","B":"Ensure that the ML model predictions are consistent with historical results.","C":"Create a different ML model for each demographic group.","D":"Measure class imbalance on the training dataset. Adapt the training process accordingly."},"correct_answer":"D"},
  {"topic":"Topic 1","number":95,"question":"Which prompting technique can protect against prompt injection attacks?","options":{"A":"Adversarial prompting","B":"Zero-shot prompting","C":"Least-to-most prompting","D":"Chain-of-thought prompting"},"correct_answer":"A"},
  {"topic":"Topic 1","number":96,"question":"A company has fine-tuned a large language model (LLM) to answer questions for a help desk. The company wants to determine if the fine-tuning has enhanced the model's accuracy. Which metric should the company use for the evaluation?","options":{"A":"Precision","B":"Time to first token","C":"F1 score","D":"Word error rate"},"correct_answer":"C"},
  {"topic":"Topic 1","number":97,"question":"A company is using Retrieval Augmented Generation (RAG) with Amazon Bedrock and Stable Diffusion to generate product images based on text descriptions. The results are often random and lack specific details. The company wants to increase the specificity of the generated images. Which solution meets these requirements?","options":{"A":"Increase the number of generation steps.","B":"Use the MASK_IMAGE_BLACK mask source option.","C":"Increase the classifier-free guidance (CFG) scale.","D":"Increase the prompt strength."},"correct_answer":"C"},
  {"topic":"Topic 1","number":98,"question":"A company wants to implement a large language model (LLM) based chatbot to provide customer service agents with real-time contextual responses to customers' inquiries. The company will use the company's policies as the knowledge base. Which solution will meet these requirements MOST cost-effectively?","options":{"A":"Retrain the LLM on the company policy data.","B":"Fine-tune the LLM on the company policy data.","C":"Implement Retrieval Augmented Generation (RAG) for in-context responses.","D":"Use pre-training and data augmentation on the company policy data."},"correct_answer":"C"},
  {"topic":"Topic 1","number":99,"question":"A company wants to create a new solution by using AWS Glue. The company has minimal programming experience with AWS Glue. Which AWS service can help the company use AWS Glue?","options":{"A":"Amazon Q Developer","B":"AWS Config","C":"Amazon Personalize","D":"Amazon Comprehend"},"correct_answer":"A"},
  {"topic":"Topic 1","number":100,"question":"A company is developing a mobile ML app that uses a phone's camera to diagnose and treat insect bites. The company wants to train an image classification model by using a diverse dataset of insect bite photos from different genders, ethnicities, and geographic locations around the world. Which principle of responsible AI does the company demonstrate in this scenario?","options":{"A":"Fairness","B":"Explainability","C":"Governance","D":"Transparency"},"correct_answer":"A"},
  {"topic":"Topic 1","number":101,"question":"A company is developing an ML model to make loan approvals. The company must implement a solution to detect bias in the model. The company must also be able to explain the model's predictions. Which solution will meet these requirements?","options":{"A":"Amazon SageMaker Clarify","B":"Amazon SageMaker Data Wrangler","C":"Amazon SageMaker Model Cards","D":"AWS AI Service Cards"},"correct_answer":"A"},
  {"topic":"Topic 1","number":102,"question":"A company has developed a generative text summarization model by using Amazon Bedrock. The company will use Amazon Bedrock automatic model evaluation capabilities. Which metric should the company use to evaluate the accuracy of the model?","options":{"A":"Area Under the ROC Curve (AUC) score","B":"F1 score","C":"BERTScore","D":"Real world knowledge (RWK) score"},"correct_answer":"C"},
  {"topic":"Topic 1","number":103,"question":"An AI practitioner wants to predict the classification of flowers based on petal length, petal width, sepal length, and sepal width. Which algorithm meets these requirements?","options":{"A":"K-nearest neighbors (k-NN)","B":"K-mean","C":"Autoregressive Integrated Moving Average (ARIMA)","D":"Linear regression"},"correct_answer":"A"},
  {"topic":"Topic 1","number":104,"question":"A company is using custom models in Amazon Bedrock for a generative AI application. The company wants to use a company managed encryption key to encrypt the model artifacts that the model customization jobs create. Which AWS service meets these requirements?","options":{"A":"AWS Key Management Service (AWS KMS)","B":"Amazon Inspector","C":"Amazon Macie","D":"AWS Secrets Manager"},"correct_answer":"A"},
  {"topic":"Topic 1","number":105,"question":"A company wants to use large language models (LLMs) to produce code from natural language code comments. Which LLM feature meets these requirements?","options":{"A":"Text summarization","B":"Text generation","C":"Text completion","D":"Text classification"},"correct_answer":"B"},
  {"topic":"Topic 1","number":106,"question":"A company is introducing a mobile app that helps users learn foreign languages. The app makes text more coherent by calling a large language model (LLM). The company collected a diverse dataset of text and supplemented the dataset with examples of more readable versions. The company wants the LLM output to resemble the provided examples. Which metric should the company use to assess whether the LLM meets these requirements?","options":{"A":"Value of the loss function","B":"Semantic robustness","C":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score","D":"Latency of the text generation"},"correct_answer":"C"},
  {"topic":"Topic 1","number":107,"question":"A company notices that its foundation model (FM) generates images that are unrelated to the prompts. The company wants to modify the prompt techniques to decrease unrelated images. Which solution meets these requirements?","options":{"A":"Use zero-shot prompts.","B":"Use negative prompts.","C":"Use positive prompts.","D":"Use ambiguous prompts."},"correct_answer":"B"},
  {"topic":"Topic 1","number":108,"question":"A company wants to use a large language model (LLM) to generate concise, feature-specific descriptions for the company's products. Which prompt engineering technique meets these requirements?","options":{"A":"Create one prompt that covers all products. Edit the responses to make the responses more specific, concise, and tailored to each product.","B":"Create prompts for each product category that highlight the key features. Include the desired output format and length for each prompt response.","C":"Include a diverse range of product features in each prompt to generate creative and unique descriptions.","D":"Provide detailed, product-specific prompts to ensure precise and customized descriptions."},"correct_answer":"B"},
  {"topic":"Topic 1","number":109,"question":"A company is developing an ML model to predict customer churn. The model performs well on the training dataset but does not accurately predict churn for new data. Which solution will resolve this issue?","options":{"A":"Decrease the regularization parameter to increase model complexity.","B":"Increase the regularization parameter to decrease model complexity.","C":"Add more features to the input data.","D":"Train the model for more epochs."},"correct_answer":"B"},
  {"topic":"Topic 1","number":110,"question":"A company is implementing intelligent agents to provide conversational search experiences for its customers. The company needs a database service that will support storage and queries of embeddings from a generative AI model as vectors in the database. Which AWS service will meet these requirements?","options":{"A":"Amazon Athena","B":"Amazon Aurora PostgreSQL","C":"Amazon Redshift","D":"Amazon EMR"},"correct_answer":"B"},
  {"topic":"Topic 1","number":111,"question":"A financial institution is building an AI solution to make loan approval decisions by using a foundation model (FM). For security and audit purposes, the company needs the AI solution's decisions to be explainable. Which factor relates to the explainability of the AI solution's decisions?","options":{"A":"Model complexity","B":"Training time","C":"Number of hyperparameters","D":"Deployment time"},"correct_answer":"A"},
  {"topic":"Topic 1","number":112,"question":"A pharmaceutical company wants to analyze user reviews of new medications and provide a concise overview for each medication. Which solution meets these requirements?","options":{"A":"Create a time-series forecasting model to analyze the medication reviews by using Amazon Personalize.","B":"Create medication review summaries by using Amazon Bedrock large language models (LLMs).","C":"Create a classification model that categorizes medications into different groups by using Amazon SageMaker.","D":"Create medication review summaries by using Amazon Rekognition."},"correct_answer":"B"},
  {"topic":"Topic 1","number":113,"question":"A company wants to build a lead prioritization application for its employees to contact potential customers. The application must give employees the ability to view and adjust the weights assigned to different variables in the model based on domain knowledge and expertise. Which ML model type meets these requirements?","options":{"A":"Logistic regression model","B":"Deep learning model built on principal components","C":"K-nearest neighbors (k-NN) model","D":"Neural network"},"correct_answer":"A"},
  {"topic":"Topic 1","number":115,"question":"Which strategy will determine if a foundation model (FM) effectively meets business objectives?","options":{"A":"Evaluate the model's performance on benchmark datasets.","B":"Analyze the model's architecture and hyperparameters.","C":"Assess the model's alignment with specific use cases.","D":"Measure the computational resources required for model deployment."},"correct_answer":"C"},
  {"topic":"Topic 1","number":116,"question":"A company needs to train an ML model to classify images of different types of animals. The company has a large dataset of labeled images and will not label more data. Which type of learning should the company use to train the model?","options":{"A":"Supervised learning","B":"Unsupervised learning","C":"Reinforcement learning","D":"Active learning"},"correct_answer":"A"},
  {"topic":"Topic 1","number":117,"question":"Which phase of the ML lifecycle determines compliance and regulatory requirements?","options":{"A":"Feature engineering","B":"Model training","C":"Data collection","D":"Business goal identification"},"correct_answer":"D"},
  {"topic":"Topic 1","number":118,"question":"A food service company wants to develop an ML model to help decrease daily food waste and increase sales revenue. The company needs to continuously improve the model's accuracy. Which solution meets these requirements?","options":{"A":"Use Amazon SageMaker and iterate with newer data.","B":"Use Amazon Personalize and iterate with historical data.","C":"Use Amazon CloudWatch to analyze customer orders.","D":"Use Amazon Rekognition to optimize the model."},"correct_answer":"A"},
  {"topic":"Topic 1","number":119,"question":"A company has developed an ML model to predict real estate sale prices. The company wants to deploy the model to make predictions without managing servers or infrastructure. Which solution meets these requirements?","options":{"A":"Deploy the model on an Amazon EC2 instance.","B":"Deploy the model on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster.","C":"Deploy the model by using Amazon CloudFront with an Amazon S3 integration.","D":"Deploy the model by using an Amazon SageMaker endpoint."},"correct_answer":"D"},
  {"topic":"Topic 1","number":120,"question":"A company wants to develop an AI application to help its employees check open customer claims, identify details for a specific claim, and access documents for a claim. Which solution meets these requirements?","options":{"A":"Use Agents for Amazon Bedrock with Amazon Fraud Detector to build the application.","B":"Use Agents for Amazon Bedrock with Amazon Bedrock knowledge bases to build the application.","C":"Use Amazon Personalize with Amazon Bedrock knowledge bases to build the application.","D":"Use Amazon SageMaker to build the application by training a new ML model."},"correct_answer":"B"},
  {"topic":"Topic 1","number":121,"question":"A company wants to develop a large language model (LLM) application that summarizes the company's internal reports. The application must identify and classify any sensitive information, such as credit card numbers and Social Security numbers, in the reports. Which solution meets these requirements?","options":{"A":"Use Amazon Textract to identify sensitive information in the reports.","B":"Use Amazon Macie to detect sensitive data within the reports.","C":"Use Amazon Comprehend to classify the sentiment of the reports.","D":"Use Amazon Transcribe to transcribe the reports."},"correct_answer":"B"},
  {"topic":"Topic 1","number":122,"question":"An AI practitioner is using Amazon Bedrock to build a generative AI application. The AI practitioner must ensure that the application is responsible, ethical, and safe for all users. Which solution meets these requirements with the LEAST amount of operational overhead?","options":{"A":"Use Amazon GuardDuty to monitor the application for any security threats.","B":"Use Guardrails for Amazon Bedrock to implement safety policies.","C":"Use AWS CodeCommit to store all the application code and track changes.","D":"Use Amazon CloudWatch to monitor the performance metrics of the application."},"correct_answer":"B"},
  {"topic":"Topic 1","number":123,"question":"A company is using Amazon Bedrock with a foundation model (FM) for a text generation task. The company wants to make the model responses more diverse and creative without changing the prompt. Which inference parameter should the company modify to meet this requirement?","options":{"A":"Increase the temperature value.","B":"Decrease the temperature value.","C":"Increase the Top K value.","D":"Decrease the maximum output tokens."},"correct_answer":"A"},
  {"topic":"Topic 1","number":124,"question":"A company is building an AI application to assist developers in writing code. The company wants to use Amazon Q Developer. Which task is Amazon Q Developer able to perform?","options":{"A":"Translating text documents from one language to another","B":"Generating and debugging code","C":"Predicting stock market trends","D":"Performing sentiment analysis on customer reviews"},"correct_answer":"B"},
  {"topic":"Topic 1","number":125,"question":"A company is creating a large language model (LLM) to translate internal documents to Spanish. The company needs to evaluate the model's output quality. Which metric meets this requirement?","options":{"A":"Bilingual Evaluation Understudy (BLEU) score","B":"Mean squared error (MSE)","C":"Area Under the ROC Curve (AUC)","D":"Receiver Operating Characteristic (ROC) curve"},"correct_answer":"A"},
  {"topic":"Topic 1","number":126,"question":"A company wants to use a generative AI model to create photorealistic images from text prompts. Which model is suitable for this task?","options":{"A":"Foundation models (FMs) from Amazon Bedrock","B":"Diffusion models","C":"Large language models (LLMs)","D":"Recommendation models"},"correct_answer":"B"},
  {"topic":"Topic 1","number":127,"question":"An AI practitioner wants to build an application by using a foundation model (FM) for image generation. The AI practitioner notices that the generated images are not precise and need to be refined. Which parameter should the AI practitioner modify to refine the images?","options":{"A":"Seed","B":"Temperature","C":"Top P","D":"Epochs"},"correct_answer":"A"},
  {"topic":"Topic 1","number":128,"question":"A company has built an ML model to predict customer churn. The company wants to deploy the model in a serverless environment and needs the ability to handle a variable rate of inference requests. Which Amazon SageMaker feature meets these requirements?","options":{"A":"Amazon SageMaker Serverless Inference","B":"Amazon SageMaker Asynchronous Inference","C":"Amazon SageMaker Batch Transform","D":"Amazon SageMaker Real-Time Inference"},"correct_answer":"A"},
  {"topic":"Topic 1","number":129,"question":"A company wants to build a generative AI application that summarizes long articles by using a large language model (LLM) from Amazon Bedrock. The application needs to retrieve relevant snippets from the articles and use the snippets to generate a summary. Which feature will meet this requirement?","options":{"A":"Prompt engineering","B":"Foundation model (FM) training","C":"Agents for Amazon Bedrock","D":"Fine-tuning"},"correct_answer":"C"},
  {"topic":"Topic 1","number":130,"question":"A company wants to use a large language model (LLM) on Amazon Bedrock to answer questions about the company's internal knowledge base. Which approach will MOST likely result in the LLM providing accurate answers?","options":{"A":"Use zero-shot prompting to minimize the context provided to the LLM.","B":"Provide a detailed prompt that includes only the user's question.","C":"Implement Retrieval Augmented Generation (RAG) by using the knowledge base.","D":"Use few-shot prompting to include examples of unrelated question-and-answer pairs."},"correct_answer":"C"},
  {"topic":"Topic 1","number":131,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to use Amazon CloudWatch to monitor the performance and usage of the foundation models (FMs) that the application uses. Which metric is the MOST relevant for the company to monitor?","options":{"A":"API gateway request count","B":"Model invocation latency","C":"S3 bucket storage size","D":"Lambda function duration"},"correct_answer":"B"},
  {"topic":"Topic 1","number":132,"question":"A company wants to build a generative AI application that answers user questions about a set of documents that are stored in a private Amazon S3 bucket. The company does not want to fine-tune a foundation model (FM). Which solution will meet these requirements?","options":{"A":"Use Amazon Comprehend to extract entities from the documents and use a prompt with few-shot examples.","B":"Use Agents for Amazon Bedrock and an Amazon Bedrock knowledge base to build the application.","C":"Use Amazon Rekognition to extract text from the documents and pass the text in the prompt to the FM.","D":"Use Amazon Textract to extract tables and forms from the documents and pass the results in the prompt to the FM."},"correct_answer":"B"},
  {"topic":"Topic 1","number":133,"question":"An AI practitioner is using Amazon Bedrock to create a custom foundation model (FM). The AI practitioner must ensure that the training data does not contain any Personally Identifiable Information (PII). Which AWS service will meet this requirement?","options":{"A":"AWS Key Management Service (AWS KMS)","B":"Amazon CloudWatch","C":"Amazon Macie","D":"AWS Config"},"correct_answer":"C"},
  {"topic":"Topic 1","number":134,"question":"A company is building a generative AI solution to help its employees quickly retrieve information from the company's internal documents. The company is concerned about model hallucination. Which solution will meet this requirement?","options":{"A":"Increase the temperature parameter in the model inference settings.","B":"Use Retrieval Augmented Generation (RAG) to ground the model responses in the source documents.","C":"Use few-shot prompting to provide multiple examples of hallucinated responses to the model.","D":"Increase the maximum length of output tokens in the model inference settings."},"correct_answer":"B"},
  {"topic":"Topic 1","number":135,"question":"An AI practitioner needs to train a deep learning model for an image classification task. The AI practitioner wants to use a pre-trained model and modify the model's last layer to adapt the model to the new classification task. Which technique meets this requirement?","options":{"A":"Transfer learning","B":"Unsupervised learning","C":"Reinforcement learning","D":"Anomaly detection"},"correct_answer":"A"},
  {"topic":"Topic 1","number":136,"question":"A company is developing an ML model to predict customer behavior. The model's performance decreases significantly when the model encounters new data that is outside the model's training range. Which solution will resolve this issue?","options":{"A":"Decrease the size of the training dataset.","B":"Increase the complexity of the model by adding more layers.","C":"Decrease the complexity of the model by using regularization techniques.","D":"Train the model for more epochs."},"correct_answer":"C"},
  {"topic":"Topic 1","number":137,"question":"Which prompting technique enables a large language model (LLM) to perform tasks and provide responses by using a step-by-step thinking process?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Adversarial prompting"},"correct_answer":"C"},
  {"topic":"Topic 1","number":138,"question":"Which option is an ethical consideration when designing and implementing an AI-powered content moderation system?","options":{"A":"Maximizing the model's inference speed","B":"Ensuring fair and consistent treatment across different user groups","C":"Minimizing the computational cost of the model","D":"Optimizing the model's training time"},"correct_answer":"B"},
  {"topic":"Topic 1","number":139,"question":"A company wants to develop a text-to-speech application to read customer reviews aloud. Which AWS service meets this requirement?","options":{"A":"Amazon Transcribe","B":"Amazon Polly","C":"Amazon Textract","D":"Amazon Comprehend"},"correct_answer":"B"},
  {"topic":"Topic 1","number":140,"question":"A company wants to build an AI application by using a foundation model (FM) from Amazon Bedrock. The company needs to control the FM's behavior to restrict output to a specific topic and tone. Which solution meets these requirements?","options":{"A":"Use Amazon Textract to analyze the output.","B":"Use prompt engineering.","C":"Use Amazon Comprehend to analyze the output.","D":"Use Amazon Transcribe to analyze the output."},"correct_answer":"B"},
  {"topic":"Topic 1","number":141,"question":"A company is building a generative AI solution to assist its employees in writing marketing emails. The company is concerned about the model generating content that violates the company's brand guidelines. Which solution will reduce this risk?","options":{"A":"Include negative examples in the training data to show the model content that violates brand guidelines.","B":"Increase the temperature parameter to encourage more diverse and creative content generation.","C":"Implement a post-processing filter to review and modify content that violates brand guidelines.","D":"Decrease the maximum output token length to limit the amount of content the model can generate."},"correct_answer":"C"},
  {"topic":"Topic 1","number":142,"question":"A company wants to build a generative AI solution to create product descriptions from a product database. The company is using Amazon Bedrock and is concerned about the quality of the generated text. Which solution will evaluate the quality of the generated text?","options":{"A":"Use Amazon Rekognition to classify the product images.","B":"Use Amazon Polly to convert the text to speech.","C":"Use Amazon Comprehend to perform sentiment analysis.","D":"Use Amazon Bedrock automatic model evaluation."},"correct_answer":"D"},
  {"topic":"Topic 1","number":143,"question":"A company needs to implement an AI solution to automatically classify incoming customer support tickets into predefined categories. Which approach is MOST suitable for this task?","options":{"A":"Unsupervised learning with clustering models","B":"Supervised learning with a classification model","C":"Reinforcement learning with a reward system","D":"Generative AI with a large language model (LLM)"},"correct_answer":"B"},
  {"topic":"Topic 1","number":144,"question":"A company wants to create an AI application to identify and categorize objects in images. The company needs a solution with a pre-trained model. Which AWS service meets this requirement?","options":{"A":"Amazon Rekognition","B":"Amazon Transcribe","C":"Amazon Comprehend","D":"Amazon Personalize"},"correct_answer":"A"},
  {"topic":"Topic 1","number":145,"question":"A company is building a large language model (LLM) application by using Amazon Bedrock. The company wants to use a knowledge base to retrieve specific information from private documents. Which solution will meet this requirement?","options":{"A":"Fine-tune the LLM with the documents.","B":"Use few-shot prompting with the documents.","C":"Create an Amazon Bedrock knowledge base.","D":"Use Amazon S3 to store the documents."},"correct_answer":"C"},
  {"topic":"Topic 1","number":146,"question":"A company wants to use a large language model (LLM) on Amazon Bedrock to summarize complex scientific documents. The company needs the summaries to be accurate and highly specific to the context of the document. Which prompting strategy should the company use to meet these requirements?","options":{"A":"Zero-shot prompting with a short, generic prompt.","B":"Few-shot prompting with examples of generic summarization.","C":"Chain-of-thought prompting to encourage logical steps and reasoning.","D":"Adversarial prompting to test the model's resistance to attacks."},"correct_answer":"C"},
  {"topic":"Topic 1","number":147,"question":"Which solution describes a capability of Agents for Amazon Bedrock?","options":{"A":"Generating code for infrastructure as code templates.","B":"Creating vector embeddings for data stored in Amazon S3.","C":"Automating complex business tasks and accessing systems outside of Bedrock.","D":"Evaluating the performance of foundation models (FMs)."},"correct_answer":"C"},
  {"topic":"Topic 1","number":148,"question":"A company wants to build a generative AI solution to help its employees create technical documentation from meeting transcripts. The company needs the solution to maintain high quality and consistency in the generated documents. Which solution meets these requirements?","options":{"A":"Use zero-shot prompting to minimize the context provided to the model.","B":"Use few-shot prompting with high-quality examples of technical documentation.","C":"Increase the temperature parameter to encourage more diverse outputs.","D":"Decrease the maximum output token length to ensure brief summaries."},"correct_answer":"B"},
  {"topic":"Topic 1","number":149,"question":"A company is using Amazon Bedrock to develop a generative AI application. The company wants to evaluate the quality of the model's generated text for grammatical correctness and coherence. Which metric will meet this requirement?","options":{"A":"Loss function value","B":"Perplexity","C":"Latency","D":"R-squared score"},"correct_answer":"B"},
  {"topic":"Topic 1","number":150,"question":"A company needs to implement an AI solution to identify and flag inappropriate or offensive images uploaded by users. Which AWS service meets this requirement?","options":{"A":"Amazon Textract","B":"Amazon Transcribe","C":"Amazon Rekognition","D":"Amazon Comprehend"},"correct_answer":"C"},
  {"topic":"Topic 1","number":151,"question":"A company wants to develop an ML model to predict a continuous numerical value (for example, housing prices). Which type of ML task is this?","options":{"A":"Classification","B":"Regression","C":"Clustering","D":"Anomaly detection"},"correct_answer":"B"},
  {"topic":"Topic 1","number":152,"question":"A company is using a large language model (LLM) to generate code snippets. The company is concerned about the LLM generating code that contains security vulnerabilities. Which action will reduce this risk?","options":{"A":"Increase the temperature parameter to encourage more creative code.","B":"Use Guardrails for Amazon Bedrock to filter out harmful or insecure content.","C":"Decrease the maximum output token length to limit the code size.","D":"Use few-shot prompting with examples of vulnerable code."},"correct_answer":"B"},
  {"topic":"Topic 1","number":153,"question":"A company wants to implement a serverless solution to run real-time predictions for its ML models. The company needs to minimize infrastructure management and pay only for the requests served. Which Amazon SageMaker feature meets these requirements?","options":{"A":"Amazon SageMaker Serverless Inference","B":"Amazon SageMaker Real-Time Inference with provisioned instances","C":"Amazon SageMaker Asynchronous Inference","D":"Amazon SageMaker Batch Transform"},"correct_answer":"A"},
  {"topic":"Topic 1","number":154,"question":"An AI practitioner is using a foundation model (FM) from Amazon Bedrock to generate marketing copy. The AI practitioner wants the model to be more deterministic, producing the same output for the same input prompt. Which parameter should the AI practitioner modify to meet this requirement?","options":{"A":"Increase the Top K value.","B":"Decrease the temperature value.","C":"Increase the maximum output tokens.","D":"Increase the prompt strength."},"correct_answer":"B"},
  {"topic":"Topic 1","number":155,"question":"A company is using Amazon Bedrock to develop a generative AI application. The company wants to deploy its custom fine-tuned model for production use with guaranteed throughput. Which Amazon Bedrock pricing model meets this requirement?","options":{"A":"On-Demand","B":"Model customization","C":"Provisioned Throughput","D":"Spot Instance"},"correct_answer":"C"},
  {"topic":"Topic 1","number":156,"question":"A company wants to build a generative AI application that summarizes customer feedback. The company is concerned about the model generating biased or unfair summaries. Which solution will reduce this risk?","options":{"A":"Implement a post-processing step to filter out all negative sentiment.","B":"Use Amazon SageMaker Clarify to detect and mitigate bias in the model's output.","C":"Increase the temperature parameter to promote more diverse summaries.","D":"Use only a small, homogeneous subset of the customer feedback for summarization."},"correct_answer":"B"},
  {"topic":"Topic 1","number":157,"question":"An AI practitioner wants to build a recommendation system for a website. The AI practitioner needs to identify groups of users who have similar browsing behavior to personalize content for each group. Which type of ML algorithm should the AI practitioner use?","options":{"A":"Classification","B":"Regression","C":"Clustering","D":"Reinforcement learning"},"correct_answer":"C"},
  {"topic":"Topic 1","number":158,"question":"A company is using a large language model (LLM) on Amazon Bedrock to generate creative content. The company is concerned about the model inadvertently generating content that infringes on existing copyrights. Which action will reduce this risk?","options":{"A":"Increase the temperature parameter to encourage novelty.","B":"Implement a content review process to check generated output against known copyrighted material.","C":"Decrease the maximum output token length to limit content size.","D":"Use few-shot prompting with examples of copyrighted material."},"correct_answer":"B"},
  {"topic":"Topic 1","number":159,"question":"A company wants to develop a large language model (LLM) application that summarizes long legal documents. The company is concerned about the LLM omitting critical details in the summaries. Which solution will reduce this risk?","options":{"A":"Increase the temperature parameter to encourage more creative responses.","B":"Use few-shot prompting with examples of very short, generic summaries.","C":"Use a prompt that explicitly instructs the LLM to include all critical legal details.","D":"Decrease the maximum output token length to ensure conciseness."},"correct_answer":"C"},
  {"topic":"Topic 1","number":160,"question":"A company is developing an ML model for credit risk assessment. The company must ensure that the model's decision-making process is transparent and that the model's output can be easily understood by regulators. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Accountability","C":"Explainability","D":"Robustness"},"correct_answer":"C"},
  {"topic":"Topic 1","number":161,"question":"A company wants to develop a large language model (LLM) application that summarizes long technical documents. The company is concerned about the quality of the summaries. Which evaluation metric is MOST suitable for measuring the quality of the generated summaries?","options":{"A":"F1 score","B":"Mean squared error (MSE)","C":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score","D":"Area Under the ROC Curve (AUC)"},"correct_answer":"C"},
  {"topic":"Topic 1","number":162,"question":"A company is using Amazon Bedrock with a foundation model (FM) for a text generation task. The company wants to evaluate the model's output to ensure that the content is original and not plagiarized. Which technique will meet this requirement?","options":{"A":"Use the BLEU score to compare the generated text with a reference text.","B":"Use a content similarity checker to compare the generated text with external sources.","C":"Increase the temperature parameter to encourage more diverse output.","D":"Decrease the maximum output token length to limit the content size."},"correct_answer":"B"},
  {"topic":"Topic 1","number":163,"question":"A company wants to use a large language model (LLM) to perform sentiment analysis on customer reviews. The company has a small dataset of labeled examples. Which prompting technique should the company use to achieve high accuracy with this limited dataset?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Adversarial prompting"},"correct_answer":"B"},
  {"topic":"Topic 1","number":164,"question":"An AI practitioner is using Amazon Bedrock to build a generative AI application. The AI practitioner needs to ensure that the application can access and use external tools and APIs to complete complex, multi-step tasks. Which Amazon Bedrock feature meets this requirement?","options":{"A":"Guardrails for Amazon Bedrock","B":"Agents for Amazon Bedrock","C":"Amazon Bedrock knowledge bases","D":"Automatic model evaluation"},"correct_answer":"B"},
  {"topic":"Topic 1","number":165,"question":"A company is developing an ML model to classify images of products. The company wants to use a pre-trained image classification model and adapt it to the company's specific product categories. Which technique meets this requirement?","options":{"A":"Transfer learning","B":"Unsupervised learning","C":"Reinforcement learning","D":"Data augmentation"},"correct_answer":"A"},
  {"topic":"Topic 1","number":166,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to log the prompts and the generated responses for auditing and quality assurance purposes. Which solution meets this requirement?","options":{"A":"Configure AWS CloudTrail to capture the API calls.","B":"Enable invocation logging in Amazon Bedrock to Amazon CloudWatch Logs and Amazon S3.","C":"Use Amazon CloudWatch to monitor the inference metrics.","D":"Use Guardrails for Amazon Bedrock to log content filtering decisions."},"correct_answer":"B"},
  {"topic":"Topic 1","number":167,"question":"A company is developing a large language model (LLM) application that answers questions based on a large internal document repository. The company is concerned about the LLM generating responses that are incorrect or made up (hallucination). Which solution will reduce this risk?","options":{"A":"Increase the model's temperature parameter to encourage creativity.","B":"Implement Retrieval Augmented Generation (RAG) to ground responses in the documents.","C":"Use few-shot prompting with examples of inaccurate responses.","D":"Decrease the maximum output token length to ensure brief answers."},"correct_answer":"B"},
  {"topic":"Topic 1","number":168,"question":"An AI practitioner wants to build a recommendation system for a streaming service. The practitioner needs to predict the rating a user will give to a movie they have not yet watched. Which type of ML task is this?","options":{"A":"Classification","B":"Regression","C":"Clustering","D":"Anomaly detection"},"correct_answer":"B"},
  {"topic":"Topic 1","number":169,"question":"A company is building an ML model to predict customer churn. The company wants to use a model that is inherently easy to interpret and explain to non-technical stakeholders. Which type of model meets this requirement?","options":{"A":"Deep neural network","B":"Support vector machine","C":"Decision tree","D":"Random forest"},"correct_answer":"C"},
  {"topic":"Topic 1","number":170,"question":"A company wants to use a generative AI model to create marketing slogans. The company needs the generated slogans to be highly creative and diverse. Which inference parameter should the company increase to meet this requirement?","options":{"A":"Temperature","B":"Top K","C":"Seed","D":"Maximum output tokens"},"correct_answer":"A"},
  {"topic":"Topic 1","number":171,"question":"A company is using Amazon SageMaker to train an ML model. The company must ensure that the training data, which is stored in Amazon S3, is encrypted with a company-managed key. Which AWS service meets this requirement?","options":{"A":"Amazon Macie","B":"AWS Key Management Service (AWS KMS)","C":"Amazon CloudWatch","D":"AWS Config"},"correct_answer":"B"},
  {"topic":"Topic 1","number":172,"question":"A company wants to develop a large language model (LLM) application that helps its employees write technical documentation. The company is concerned about the LLM generating content that is toxic or contains hate speech. Which solution will reduce this risk?","options":{"A":"Increase the temperature parameter to encourage creativity.","B":"Use Guardrails for Amazon Bedrock to filter out harmful content.","C":"Decrease the maximum output token length to ensure brief content.","D":"Use few-shot prompting with examples of toxic content."},"correct_answer":"B"},
  {"topic":"Topic 1","number":173,"question":"Which prompting technique can be used to improve the output of a large language model (LLM) by providing examples of the desired input and output format within the prompt?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Adversarial prompting"},"correct_answer":"B"},
  {"topic":"Topic 1","number":174,"question":"A company wants to develop an AI application that automatically converts spoken customer support calls into text transcripts. Which AWS service meets this requirement?","options":{"A":"Amazon Polly","B":"Amazon Transcribe","C":"Amazon Textract","D":"Amazon Comprehend"},"correct_answer":"B"},
  {"topic":"Topic 1","number":175,"question":"A company is using a large language model (LLM) on Amazon Bedrock to generate creative stories. The company wants to ensure that the stories are coherent and flow logically. Which evaluation metric is MOST suitable for measuring the coherence of the generated text?","options":{"A":"Perplexity","B":"F1 score","C":"Mean squared error (MSE)","D":"Area Under the ROC Curve (AUC)"},"correct_answer":"A"},
  {"topic":"Topic 1","number":176,"question":"A company wants to build an ML model to categorize emails into 'spam' or 'not spam'. Which type of ML task is this?","options":{"A":"Binary classification","B":"Multi-class classification","C":"Regression","D":"Clustering"},"correct_answer":"A"},
  {"topic":"Topic 1","number":177,"question":"A company is using Amazon Bedrock to customize a foundation model (FM). The company needs to use an existing dataset, stored in an Amazon S3 bucket, for the customization job. The company wants to ensure that the data is encrypted during transit to Amazon Bedrock. Which solution meets this requirement?","options":{"A":"Use S3 bucket policies to deny unencrypted uploads.","B":"Encrypt the data at rest in S3 using Server-Side Encryption with AWS KMS keys (SSE-KMS).","C":"Use Secure Sockets Layer/Transport Layer Security (SSL/TLS) for data transfer.","D":"Use an Amazon CloudFront distribution in front of the S3 bucket."},"correct_answer":"C"},
  {"topic":"Topic 1","number":178,"question":"A company wants to build a generative AI solution to help its employees create personalized sales emails. The company is concerned about the model generating content that reveals sensitive customer information. Which action will reduce this risk?","options":{"A":"Increase the temperature parameter to encourage creativity.","B":"Use Amazon Macie to detect and mask sensitive data in the generated output.","C":"Decrease the maximum output token length to limit the content size.","D":"Use few-shot prompting with examples of sensitive information."},"correct_answer":"B"},
  {"topic":"Topic 1","number":179,"question":"An AI practitioner is using a foundation model (FM) for text generation. The FM is producing lengthy and repetitive responses. Which inference parameter should the AI practitioner tune to prevent the model from repeating itself and improve the diversity of the output?","options":{"A":"Temperature","B":"Top P","C":"Seed","D":"Maximum output tokens"},"correct_answer":"B"},
  {"topic":"Topic 1","number":180,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to ensure that the application's performance meets the required latency Service Level Agreements (SLAs). Which Amazon Bedrock pricing model guarantees dedicated throughput?","options":{"A":"On-Demand","B":"Model customization","C":"Provisioned Throughput","D":"Spot Instance"},"correct_answer":"C"},
  {"topic":"Topic 1","number":181,"question":"A company wants to build an AI solution to detect fraudulent credit card transactions. The company has a large dataset of both normal and fraudulent transactions, with the fraudulent ones being a small fraction of the total. Which ML task is this?","options":{"A":"Binary classification","B":"Multi-class classification","C":"Regression","D":"Clustering"},"correct_answer":"A"},
  {"topic":"Topic 1","number":182,"question":"A company is using a large language model (LLM) on Amazon Bedrock to generate summaries of financial reports. The company wants to ensure that the summaries are accurate and consistent with the original reports. Which solution will meet this requirement?","options":{"A":"Increase the temperature parameter to encourage more diverse summaries.","B":"Use few-shot prompting with examples of short, generic summaries.","C":"Use a prompt that emphasizes factual accuracy and coherence.","D":"Decrease the maximum output token length to ensure brief summaries."},"correct_answer":"C"},
  {"topic":"Topic 1","number":183,"question":"A company wants to use a foundation model (FM) from Amazon Bedrock to generate code snippets. The company wants to ensure that the generated code adheres to specific style guides and best practices. Which solution meets this requirement?","options":{"A":"Increase the temperature parameter to encourage creativity.","B":"Use few-shot prompting with examples of code that follows the style guide.","C":"Decrease the maximum output token length to limit the code size.","D":"Use a prompt that only asks for the code without style instructions."},"correct_answer":"B"},
  {"topic":"Topic 1","number":184,"question":"Which principle of responsible AI is directly addressed by using Amazon SageMaker Clarify for bias detection and mitigation?","options":{"A":"Transparency","B":"Fairness","C":"Explainability","D":"Robustness"},"correct_answer":"B"},
  {"topic":"Topic 1","number":185,"question":"A company wants to develop an ML model to predict customer lifetime value (CLV). This involves predicting a continuous dollar value. Which type of ML algorithm should the company use?","options":{"A":"Classification","B":"Regression","C":"Clustering","D":"Anomaly detection"},"correct_answer":"B"},
  {"topic":"Topic 1","number":186,"question":"A company is using Amazon Bedrock with a foundation model (FM) for a text generation task. The company wants to evaluate the model's output for originality and diversity. Which metric is MOST suitable for measuring these aspects?","options":{"A":"Loss function value","B":"Perplexity","C":"Distinct n-grams (e.g., Distinct-1, Distinct-2)","D":"R-squared score"},"correct_answer":"C"},
  {"topic":"Topic 1","number":187,"question":"An AI practitioner wants to build a generative AI application that summarizes medical case notes. The application must ensure that the summaries are grounded in the facts presented in the notes. Which solution meets this requirement?","options":{"A":"Increase the temperature parameter to encourage creativity.","B":"Implement Retrieval Augmented Generation (RAG) to reference the case notes.","C":"Use few-shot prompting with examples of inaccurate summaries.","D":"Decrease the maximum output token length to ensure brief answers."},"correct_answer":"B"},
  {"topic":"Topic 1","number":188,"question":"A company is using Amazon SageMaker to deploy an ML model for real-time inference. The company needs to ensure that the model endpoint is highly available and can scale automatically to handle fluctuating traffic. Which deployment option meets these requirements?","options":{"A":"Amazon SageMaker Serverless Inference","B":"Amazon SageMaker Real-Time Inference with auto scaling","C":"Amazon SageMaker Asynchronous Inference","D":"Amazon SageMaker Batch Transform"},"correct_answer":"B"},
  {"topic":"Topic 1","number":189,"question":"A company wants to develop a large language model (LLM) application that generates creative ad copy. The company needs the LLM to provide diverse and unexpected results for A/B testing. Which inference parameter should the company increase to meet this requirement?","options":{"A":"Temperature","B":"Top K","C":"Seed","D":"Maximum output tokens"},"correct_answer":"A"},
  {"topic":"Topic 1","number":190,"question":"A company wants to build an AI application to assist its legal team by automatically extracting names, dates, and locations from legal documents. Which AWS service meets this requirement?","options":{"A":"Amazon Rekognition","B":"Amazon Transcribe","C":"Amazon Comprehend","D":"Amazon Personalize"},"correct_answer":"C"},
  {"topic":"Topic 1","number":191,"question":"A company is building an ML model to classify images of different types of cars. The company needs to ensure that the model performs equally well across different car colors, which are not features the model should be biased by. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Explainability","C":"Transparency","D":"Robustness"},"correct_answer":"A"},
  {"topic":"Topic 1","number":192,"question":"A company wants to use a large language model (LLM) on Amazon Bedrock to write technical guides. The company wants the output to be highly technical and domain-specific. Which solution is MOST likely to improve the technical nature of the output?","options":{"A":"Increase the temperature parameter to encourage creativity.","B":"Use a prompt that includes specific technical terminology and a persona of a technical writer.","C":"Decrease the maximum output token length to ensure brief answers.","D":"Use few-shot prompting with examples of non-technical writing."},"correct_answer":"B"},
  {"topic":"Topic 1","number":193,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to perform automatic evaluation of the model's output for helpfulness and harmlessness. Which feature meets this requirement?","options":{"A":"Guardrails for Amazon Bedrock","B":"Agents for Amazon Bedrock","C":"Amazon Bedrock automatic model evaluation","D":"Amazon Bedrock knowledge bases"},"correct_answer":"C"},
  {"topic":"Topic 1","number":194,"question":"Which phase of the ML lifecycle involves selecting the appropriate algorithm, choosing a framework, and splitting the data into training, validation, and test sets?","options":{"A":"Data collection","B":"Model training","C":"Model preparation and selection","D":"Model deployment"},"correct_answer":"C"},
  {"topic":"Topic 1","number":195,"question":"A company wants to use a foundation model (FM) for image generation to create new product designs. The company needs to ensure that the generated images are free of inappropriate content. Which solution meets this requirement?","options":{"A":"Increase the temperature parameter to encourage creativity.","B":"Use Guardrails for Amazon Bedrock to filter the output.","C":"Use few-shot prompting with examples of inappropriate images.","D":"Decrease the maximum output token length to limit the image size."},"correct_answer":"B"},
  {"topic":"Topic 1","number":196,"question":"A company is developing an ML model to classify images of different types of medical conditions. The company needs to use an algorithm that provides high accuracy and is suitable for multi-class classification. Which algorithm meets this requirement?","options":{"A":"Linear regression","B":"K-means clustering","C":"Convolutional neural network (CNN)","D":"Apriori algorithm"},"correct_answer":"C"},
  {"topic":"Topic 1","number":197,"question":"A company wants to build a generative AI application that summarizes long customer service chat transcripts. The company needs the summaries to capture the main points and key actions required. Which prompting technique is MOST suitable for this task?","options":{"A":"Zero-shot prompting with a simple 'summarize this' instruction.","B":"Few-shot prompting with examples of well-structured summaries that capture main points and actions.","C":"Adversarial prompting to test the model's security.","D":"Chain-of-thought prompting for a step-by-step thinking process."},"correct_answer":"B"},
  {"topic":"Topic 1","number":198,"question":"A company is using Amazon Bedrock with a foundation model (FM) for a text generation task. The company wants to customize the model's behavior without incurring the cost and time of full fine-tuning. Which technique can the company use to influence the model's output at inference time?","options":{"A":"Model architecture changes","B":"Prompt engineering","C":"Pre-training on a larger dataset","D":"Hyperparameter optimization of the base model"},"correct_answer":"B"},
  {"topic":"Topic 1","number":199,"question":"A company is developing an ML model to predict whether a customer will click on an ad ('yes' or 'no'). Which metric is MOST appropriate for evaluating this binary classification model?","options":{"A":"Mean squared error (MSE)","B":"R-squared score","C":"Area Under the ROC Curve (AUC)","D":"Perplexity"},"correct_answer":"C"},
  {"topic":"Topic 1","number":200,"question":"A company wants to use a foundation model (FM) to create a chatbot that answers questions based on a large, proprietary knowledge base. The company needs the chatbot to provide citations for its answers. Which solution meets this requirement?","options":{"A":"Increase the model's temperature parameter to encourage creativity.","B":"Implement Retrieval Augmented Generation (RAG) which often includes source citations.","C":"Use few-shot prompting with examples of uncited answers.","D":"Decrease the maximum output token length to ensure brief answers."},"correct_answer":"B"},
  {"topic":"Topic 1","number":201,"question":"A company wants to use a generative AI model to create personalized marketing images for its customers. The company needs to control the specific visual style and elements of the generated images. Which feature of generative AI models enables this control?","options":{"A":"Model architecture changes","B":"Prompt engineering","C":"Hyperparameter optimization","D":"Transfer learning"},"correct_answer":"B"},
  {"topic":"Topic 1","number":202,"question":"A company wants to develop a large language model (LLM) application that summarizes meeting transcripts. The company needs to evaluate the model's output for factual accuracy and adherence to the main points of the transcript. Which evaluation metric is MOST suitable for this task?","options":{"A":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score","B":"Bilingual Evaluation Understudy (BLEU) score","C":"Mean squared error (MSE)","D":"Area Under the ROC Curve (AUC)"},"correct_answer":"A"},
  {"topic":"Topic 1","number":203,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to deploy a fine-tuned model for production use and needs to reserve a specific amount of throughput to ensure predictable latency. Which Amazon Bedrock pricing model meets this requirement?","options":{"A":"On-Demand","B":"Model customization","C":"Spot Instance","D":"Provisioned Throughput"},"correct_answer":"D"},
  {"topic":"Topic 1","number":204,"question":"An AI practitioner is building a deep learning model for image classification. The model performs well on the training data but poorly on unseen test data. Which action should the AI practitioner take to mitigate this issue?","options":{"A":"Remove layers from the model to decrease complexity.","B":"Decrease the regularization parameter to increase model complexity.","C":"Increase the regularization parameter to reduce model complexity.","D":"Decrease the size of the training dataset."},"correct_answer":"C"},
  {"topic":"Topic 1","number":205,"question":"A company wants to develop a large language model (LLM) application that performs multi-step tasks, such as looking up product inventory and then generating a personalized email to a customer. Which Amazon Bedrock feature enables the LLM to perform these actions?","options":{"A":"Guardrails for Amazon Bedrock","B":"Amazon Bedrock knowledge bases","C":"Agents for Amazon Bedrock","D":"Automatic model evaluation"},"correct_answer":"C"},
  {"topic":"Topic 1","number":206,"question":"A company is developing an ML model to predict customer churn. The company needs to use an algorithm that is suitable for classifying customers into 'churn' or 'no churn' and that is robust against overfitting. Which algorithm meets these requirements?","options":{"A":"XGBoost","B":"K-means clustering","C":"Linear regression","D":"Autoregressive Integrated Moving Average (ARIMA)"},"correct_answer":"A"},
  {"topic":"Topic 1","number":207,"question":"A company is using a large language model (LLM) to translate technical documents. The company is concerned about the LLM introducing security vulnerabilities by translating content incorrectly. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Explainability","C":"Transparency","D":"Robustness"},"correct_answer":"D"},
  {"topic":"Topic 1","number":208,"question":"A company wants to use a foundation model (FM) for image generation to create diverse and unique artwork. The company needs to adjust the inference parameters to maximize the creativity and randomness of the output. Which parameter should the company increase?","options":{"A":"Top K","B":"Temperature","C":"Seed","D":"Maximum output tokens"},"correct_answer":"B"},
  {"topic":"Topic 1","number":209,"question":"A company is developing an ML model to predict whether a patient has a specific medical condition ('positive' or 'negative'). The company is concerned about false negatives (failing to predict a positive case). Which metric is MOST important to optimize in this scenario?","options":{"A":"Precision","B":"Recall","C":"Accuracy","D":"F1 score"},"correct_answer":"B"},
  {"topic":"Topic 1","number":210,"question":"A company wants to build a generative AI application that answers questions based on a massive, constantly updated internal document library. The company needs a scalable and cost-effective way to keep the LLM responses current with the latest documents. Which solution meets this requirement?","options":{"A":"Fine-tune the LLM daily with the new documents.","B":"Manually update the LLM's system prompt with key facts from new documents.","C":"Train a new LLM from scratch monthly with the entire document library.","D":"Implement Retrieval Augmented Generation (RAG) using Amazon Bedrock knowledge bases."},"correct_answer":"D"},
  {"topic":"Topic 1","number":211,"question":"A company is training a foundation model (FM) and observes that the model's performance on the validation dataset is stagnant, while the training loss continues to decrease. Which issue is the model MOST likely experiencing?","options":{"A":"Overfitting","B":"Underfitting","C":"Data leakage","D":"Vanishing gradient"},"correct_answer":"A"},
  {"topic":"Topic 1","number":212,"question":"A company wants to build an AI application to assist its compliance team by automatically comparing newly drafted internal policies against existing regulatory texts to find similarities and potential conflicts. Which AWS service meets this requirement?","options":{"A":"Amazon Transcribe","B":"Amazon Personalize","C":"Amazon Rekognition","D":"Amazon Comprehend"},"correct_answer":"D"},
  {"topic":"Topic 1","number":213,"question":"A company wants to use a large language model (LLM) on Amazon Bedrock to generate code. The company needs to ensure that the generated code is correct and follows specific input-output patterns. Which prompting technique is MOST suitable for this task?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Adversarial prompting"},"correct_answer":"B"},
  {"topic":"Topic 1","number":214,"question":"A company wants to build an ML model to segment its customers into different groups based on their purchasing behavior without predefined labels. Which type of learning should the company use?","options":{"A":"Supervised learning","B":"Reinforcement learning","C":"Transfer learning","D":"Unsupervised learning"},"correct_answer":"D"},
  {"topic":"Topic 1","number":215,"question":"A company is building a generative AI application using an Amazon Bedrock foundation model (FM). The company must comply with privacy regulations by ensuring that PII from user inputs is not used in the model's output. Which solution meets this requirement?","options":{"A":"Use Amazon Macie to scan the model's output for PII.","B":"Increase the model's temperature parameter to encourage diverse output.","C":"Use Guardrails for Amazon Bedrock to filter PII from the input and output.","D":"Decrease the maximum output token length to limit the content."},"correct_answer":"C"},
  {"topic":"Topic 1","number":216,"question":"A company wants to use a foundation model (FM) for text generation. The company needs the FM to generate text that is grammatically correct and fluent. Which metric is MOST suitable for evaluating these aspects?","options":{"A":"F1 score","B":"Area Under the ROC Curve (AUC)","C":"Perplexity","D":"Mean squared error (MSE)"},"correct_answer":"C"},
  {"topic":"Topic 1","number":217,"question":"A company wants to use a large language model (LLM) to summarize customer feedback. The company needs to ensure that the summaries maintain the original sentiment and key themes of the feedback. Which evaluation metric is MOST suitable for this task?","options":{"A":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score","B":"Bilingual Evaluation Understudy (BLEU) score","C":"Word error rate (WER)","D":"Perplexity"},"correct_answer":"A"},
  {"topic":"Topic 1","number":218,"question":"A company is developing an ML model to classify images of different products. The company wants to use a model that provides a clear explanation of which parts of the image contributed most to the classification decision. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Transparency","C":"Robustness","D":"Explainability"},"correct_answer":"D"},
  {"topic":"Topic 1","number":219,"question":"A company is using Amazon Bedrock to customize a foundation model (FM). The company needs to use a proprietary training dataset, and a security policy requires that the dataset must be in a specific location during the customization job. Which AWS service must the dataset be stored in for Amazon Bedrock customization?","options":{"A":"Amazon S3","B":"Amazon Elastic Block Store (Amazon EBS)","C":"Amazon Elastic File System (Amazon EFS)","D":"Amazon DynamoDB"},"correct_answer":"A"},
  {"topic":"Topic 1","number":220,"question":"A company is developing a large language model (LLM) application that generates legal summaries. The company is concerned about model hallucination (generating factually incorrect information). Which solution will mitigate this risk?","options":{"A":"Increase the temperature parameter to encourage creative output.","B":"Use few-shot prompting with examples of inaccurate summaries.","C":"Implement Retrieval Augmented Generation (RAG) to ground the responses in source legal texts.","D":"Decrease the maximum output token length to ensure brief summaries."},"correct_answer":"C"},
  {"topic":"Topic 1","number":221,"question":"A company wants to develop an ML model to predict customer churn. The company wants to evaluate the model's ability to correctly identify all customers who will churn. Which metric is MOST appropriate for this evaluation?","options":{"A":"Precision","B":"Accuracy","C":"F1 score","D":"Recall"},"correct_answer":"D"},
  {"topic":"Topic 1","number":222,"question":"A company is building a generative AI application using Amazon Bedrock. The application needs to translate a large volume of customer messages from English to French in an asynchronous, non-real-time manner. Which Amazon Bedrock deployment approach is MOST suitable for this task?","options":{"A":"Batch processing using Amazon Bedrock","B":"Real-time inference with Provisioned Throughput","C":"Real-time inference with On-Demand throughput","D":"Serverless inference using Amazon SageMaker"},"correct_answer":"A"},
  {"topic":"Topic 1","number":223,"question":"A company wants to use a foundation model (FM) for image generation to create a logo. The company wants to ensure that the logo generated is visually different each time the same prompt is used, to explore many options. Which parameter should the company avoid setting to achieve this requirement?","options":{"A":"Temperature","B":"Seed","C":"Top P","D":"Classifier-Free Guidance (CFG) scale"},"correct_answer":"B"},
  {"topic":"Topic 1","number":224,"question":"A company is using Amazon SageMaker to develop an ML model. The company needs to visualize and transform raw data, and then automatically select the best model for a predictive task without writing code. Which Amazon SageMaker feature meets these requirements?","options":{"A":"Amazon SageMaker Studio Notebooks","B":"Amazon SageMaker Canvas","C":"Amazon SageMaker Ground Truth","D":"Amazon SageMaker Clarify"},"correct_answer":"B"},
  {"topic":"Topic 1","number":225,"question":"A company wants to develop a large language model (LLM) application that helps call center agents by providing real-time, context-aware answers. The company has a diverse set of documents (PDFs, HTML files) in a private repository. Which combination of features will meet this requirement? (Choose two.)","options":{"A":"Amazon Bedrock knowledge bases","B":"Fine-tuning the LLM","C":"Retrieval Augmented Generation (RAG)","D":"Increase the temperature parameter","E":"Use Zero-shot prompting"},"correct_answer":["A","C"]},
  {"topic":"Topic 1","number":226,"question":"A company is using a foundation model (FM) for text generation. The company wants to limit the model's output to a maximum of 50 tokens to ensure conciseness. Which inference parameter should the company set?","options":{"A":"Temperature","B":"Top P","C":"Seed","D":"Maximum output tokens"},"correct_answer":"D"},
  {"topic":"Topic 1","number":227,"question":"A company is using Amazon SageMaker to train a model. The company must comply with a regulation that requires all model training and inference artifacts to be encrypted with a company-provided key. Which AWS service facilitates this encryption?","options":{"A":"AWS Key Management Service (AWS KMS)","B":"Amazon Macie","C":"AWS Config","D":"Amazon Inspector"},"correct_answer":"A"},
  {"topic":"Topic 1","number":228,"question":"A company wants to use a large language model (LLM) to perform quality assurance checks on newly written articles by identifying grammar mistakes. Which LLM feature is MOST suitable for this task?","options":{"A":"Text summarization","B":"Text classification","C":"Text correction and editing","D":"Text generation"},"correct_answer":"C"},
  {"topic":"Topic 1","number":229,"question":"A company is developing an ML model to classify images of different types of furniture. The company needs to use an algorithm that is suitable for multi-class classification and can handle high-dimensional image data. Which algorithm meets this requirement?","options":{"A":"Convolutional neural network (CNN)","B":"Linear regression","C":"K-means clustering","D":"Apriori algorithm"},"correct_answer":"A"},
  {"topic":"Topic 1","number":230,"question":"A company wants to use a large language model (LLM) to generate creative marketing copy. The company is concerned that the LLM might generate content that promotes illegal activities. Which solution will reduce this risk?","options":{"A":"Increase the temperature parameter to encourage creativity.","B":"Use Guardrails for Amazon Bedrock to filter for content that promotes illegal activities.","C":"Decrease the maximum output token length to limit the content size.","D":"Use few-shot prompting with examples of illegal activities."},"correct_answer":"B"},
  {"topic":"Topic 1","number":231,"question":"A company is building a generative AI application that summarizes long text documents. The company is concerned about the quality of the summaries. Which evaluation metric is MOST suitable for measuring the informativeness and correctness of the generated summaries?","options":{"A":"Perplexity","B":"F1 score","C":"Mean squared error (MSE)","D":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score"},"correct_answer":"D"},
  {"topic":"Topic 1","number":232,"question":"A company wants to develop an ML model to recommend products to users based on past purchases. The company has historical data of user-product interactions. Which type of ML algorithm should the company use?","options":{"A":"Clustering","B":"Regression","C":"Binary classification","D":"Time-series forecasting"},"correct_answer":"A"},
  {"topic":"Topic 1","number":233,"question":"A company wants to use a large language model (LLM) to generate personalized responses to customer emails. The company needs to ensure that the tone of the response is always professional and courteous. Which prompt engineering technique is MOST suitable for this?","options":{"A":"Chain-of-thought prompting","B":"Providing a system prompt that defines the desired tone and persona.","C":"Zero-shot prompting with no tone instructions.","D":"Increasing the model's temperature."},"correct_answer":"B"},
  {"topic":"Topic 1","number":234,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to store the embeddings generated from its internal documents in a vector database for use with Retrieval Augmented Generation (RAG). Which AWS service provides vector storage capability?","options":{"A":"Amazon DynamoDB","B":"Amazon Redshift","C":"Amazon Aurora PostgreSQL with pgvector","D":"Amazon S3"},"correct_answer":"C"},
  {"topic":"Topic 1","number":235,"question":"A company is developing an ML model to predict customer churn. The company wants to ensure that the model is easily understandable and that the factors influencing the prediction can be clearly explained. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Robustness","C":"Explainability","D":"Transparency"},"correct_answer":"C"},
  {"topic":"Topic 1","number":236,"question":"A company wants to use a foundation model (FM) for image generation. The company needs to ensure that the model does not generate images containing nudity or violence. Which solution will meet this requirement?","options":{"A":"Use Guardrails for Amazon Bedrock to filter the output content.","B":"Increase the temperature parameter for creativity.","C":"Decrease the maximum output token length.","D":"Use few-shot prompting with examples of benign images."},"correct_answer":"A"},
  {"topic":"Topic 1","number":237,"question":"A company is using Amazon SageMaker to deploy a model for real-time inference. The company expects traffic to be sporadic with long periods of inactivity, and wants a cost-effective solution that scales to zero. Which deployment option meets these requirements?","options":{"A":"Amazon SageMaker Real-Time Inference with provisioned instances","B":"Amazon SageMaker Asynchronous Inference","C":"Amazon SageMaker Batch Transform","D":"Amazon SageMaker Serverless Inference"},"correct_answer":"D"},
  {"topic":"Topic 1","number":238,"question":"A company wants to develop a large language model (LLM) application that translates text. The company needs to evaluate the translation quality against human-translated references. Which evaluation metric is MOST suitable for this task?","options":{"A":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score","B":"Bilingual Evaluation Understudy (BLEU) score","C":"Mean squared error (MSE)","D":"F1 score"},"correct_answer":"B"},
  {"topic":"Topic 1","number":239,"question":"A company is using a large language model (LLM) to generate creative content. The company wants to influence the output by instructing the model to focus on a specific narrative style (e.g., formal, casual, technical). Which technique should the company use?","options":{"A":"Prompt engineering","B":"Fine-tuning the model","C":"Increasing the Top K parameter","D":"Setting the Seed parameter"},"correct_answer":"A"},
  {"topic":"Topic 1","number":240,"question":"A company is developing an ML model for a loan approval process. The company observes that the model's rejection rate is significantly higher for a specific demographic group, indicating bias. Which solution should the company implement to address this issue?","options":{"A":"Remove all demographic data from the training set.","B":"Increase the model's complexity by adding more layers.","C":"Use Amazon SageMaker Clarify to detect and mitigate bias in the training data and model.","D":"Set the model's temperature parameter to zero."},"correct_answer":"C"},
  {"topic":"Topic 1","number":241,"question":"A company wants to develop a large language model (LLM) application that helps its employees draft internal memos. The company needs to ensure that the LLM's responses are grounded in facts from the company's internal documents. Which solution will meet this requirement?","options":{"A":"Increase the model's temperature parameter to encourage creative output.","B":"Use few-shot prompting with examples of inaccurate memos.","C":"Implement Retrieval Augmented Generation (RAG) to connect the LLM to the internal documents.","D":"Decrease the maximum output token length to ensure brief summaries."},"correct_answer":"C"},
  {"topic":"Topic 1","number":242,"question":"A company is using Amazon Bedrock with a foundation model (FM) for text generation. The company wants to prevent the FM from generating content that could be interpreted as financial or legal advice. Which feature of Amazon Bedrock meets this requirement?","options":{"A":"Amazon Bedrock knowledge bases","B":"Agents for Amazon Bedrock","C":"Guardrails for Amazon Bedrock","D":"Automatic model evaluation"},"correct_answer":"C"},
  {"topic":"Topic 1","number":243,"question":"A company wants to use a large language model (LLM) to extract structured data (e.g., names, addresses, dates) from unstructured legal documents. Which LLM feature is MOST suitable for this task?","options":{"A":"Text summarization","B":"Named entity recognition (NER)","C":"Text classification","D":"Text generation"},"correct_answer":"B"},
  {"topic":"Topic 1","number":244,"question":"A company is developing an ML model to forecast monthly sales revenue. This involves predicting a continuous numerical value over time. Which type of ML algorithm should the company use?","options":{"A":"Classification","B":"Regression","C":"Clustering","D":"Anomaly detection"},"correct_answer":"B"},
  {"topic":"Topic 1","number":245,"question":"An AI practitioner is fine-tuning a foundation model (FM) on a new, smaller dataset. The practitioner wants to ensure that the FM retains its general knowledge learned during pre-training while adapting to the new task. Which fine-tuning technique is MOST suitable?","options":{"A":"Full fine-tuning (updating all weights)","B":"Parameter-Efficient Fine-Tuning (PEFT), such as LoRA","C":"Pre-training on the new dataset","D":"Using zero-shot prompting"},"correct_answer":"B"},
  {"topic":"Topic 1","number":246,"question":"A company wants to build an AI application to assist its marketing team by automatically generating personalized product recommendations for website visitors. Which AWS service meets this requirement?","options":{"A":"Amazon Textract","B":"Amazon Personalize","C":"Amazon Rekognition","D":"Amazon Transcribe"},"correct_answer":"B"},
  {"topic":"Topic 1","number":247,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to use a prompt engineering technique that instructs the foundation model (FM) to process a request by first breaking it down into smaller, logical steps before providing the final answer. Which technique meets this requirement?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Adversarial prompting"},"correct_answer":"C"},
  {"topic":"Topic 1","number":248,"question":"A company is using Amazon SageMaker to deploy an ML model for real-time inference. The company expects traffic to be sporadic with long periods of inactivity, and wants to minimize costs by only paying for the time the model is actively processing requests. Which deployment option meets these requirements?","options":{"A":"Amazon SageMaker Real-Time Inference with provisioned instances","B":"Amazon SageMaker Asynchronous Inference","C":"Amazon SageMaker Batch Transform","D":"Amazon SageMaker Serverless Inference"},"correct_answer":"D"},
  {"topic":"Topic 1","number":249,"question":"A company is developing an ML model to classify satellite images into 'forest', 'urban', or 'water'. The company needs to use an algorithm suitable for multi-class image classification. Which algorithm meets this requirement?","options":{"A":"Linear regression","B":"K-means clustering","C":"Convolutional neural network (CNN)","D":"Apriori algorithm"},"correct_answer":"C"},
  {"topic":"Topic 1","number":250,"question":"A company wants to build a generative AI solution to help its legal team by summarizing lengthy contracts. The company needs to ensure that the summaries are consistent and do not omit critical clauses. Which solution will meet this requirement?","options":{"A":"Increase the temperature parameter to encourage diverse output.","B":"Use a few-shot prompt with examples of high-quality, comprehensive legal summaries.","C":"Decrease the maximum output token length to ensure conciseness.","D":"Use an adversarial prompt to test the model's security."},"correct_answer":"B"},
  {"topic":"Topic 1","number":251,"question":"A company is using Amazon Bedrock with a foundation model (FM) for text generation. The company wants to make the model responses more deterministic and factual. Which inference parameter should the company decrease to meet this requirement?","options":{"A":"Temperature","B":"Top K","C":"Maximum output tokens","D":"Prompt strength"},"correct_answer":"A"},
  {"topic":"Topic 1","number":252,"question":"A company wants to develop a large language model (LLM) application to translate legal documents. The company is concerned about the quality of the translation and needs to evaluate its accuracy against professional translations. Which evaluation metric is MOST suitable for this task?","options":{"A":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score","B":"Bilingual Evaluation Understudy (BLEU) score","C":"Mean squared error (MSE)","D":"F1 score"},"correct_answer":"B"},
  {"topic":"Topic 1","number":253,"question":"A company wants to develop an ML model to predict whether a customer will renew their subscription ('yes' or 'no'). The company is concerned about false positives (predicting renewal when the customer will not). Which metric is MOST important to optimize in this scenario?","options":{"A":"Recall","B":"Precision","C":"Accuracy","D":"F1 score"},"correct_answer":"B"},
  {"topic":"Topic 1","number":254,"question":"A company is using Amazon Bedrock to build a generative AI application. The application needs to perform complex, multi-step operations that involve calling the company's internal inventory system API and then generating a response. Which feature of Amazon Bedrock enables this capability?","options":{"A":"Amazon Bedrock knowledge bases","B":"Guardrails for Amazon Bedrock","C":"Agents for Amazon Bedrock","D":"Automatic model evaluation"},"correct_answer":"C"},
  {"topic":"Topic 1","number":255,"question":"A company is developing an ML model to classify images of different animals. The company has a large dataset of labeled images. Which type of learning should the company use to train the model?","options":{"A":"Unsupervised learning","B":"Supervised learning","C":"Reinforcement learning","D":"Transfer learning"},"correct_answer":"B"},
  {"topic":"Topic 1","number":256,"question":"A company wants to use a large language model (LLM) to generate creative marketing copy. The company needs the generated text to be highly original and diverse, avoiding common phrases. Which inference parameter should the company increase to meet this requirement?","options":{"A":"Temperature","B":"Top K","C":"Seed","D":"Maximum output tokens"},"correct_answer":"A"},
  {"topic":"Topic 1","number":257,"question":"A company is developing an ML model to predict customer churn. The model performs poorly on the test set, indicating it is too simple and cannot capture the complexity of the data. Which issue is the model MOST likely experiencing?","options":{"A":"Overfitting","B":"Underfitting","C":"Data leakage","D":"Model drift"},"correct_answer":"B"},
  {"topic":"Topic 1","number":258,"question":"A company is using Amazon Bedrock to customize a foundation model (FM). The company is concerned about data privacy and needs to ensure that the customization job's training data, stored in Amazon S3, is protected. Which solution meets this requirement?","options":{"A":"Use Amazon Macie to scan the S3 bucket for PII.","B":"Encrypt the S3 data using Server-Side Encryption with AWS KMS keys (SSE-KMS).","C":"Use Amazon CloudWatch to monitor S3 API calls.","D":"Decrease the number of customization epochs."},"correct_answer":"B"},
  {"topic":"Topic 1","number":259,"question":"A company wants to use a foundation model (FM) for image generation to create images of people for marketing campaigns. The company is concerned about generating images that are harmful or perpetuate negative stereotypes. Which principle of responsible AI is the company focusing on?","options":{"A":"Explainability","B":"Fairness","C":"Robustness","D":"Transparency"},"correct_answer":"B"},
  {"topic":"Topic 1","number":260,"question":"A company wants to build a generative AI solution to help its customer support team. The solution must provide immediate, accurate answers based on a set of internal technical manuals. The company requires the solution to be low-latency and handle variable traffic. Which solution meets these requirements?","options":{"A":"Fine-tune a large language model (LLM) on the manuals and deploy with Provisioned Throughput.","B":"Implement Retrieval Augmented Generation (RAG) using Amazon Bedrock knowledge bases and On-Demand throughput.","C":"Use zero-shot prompting with the LLM and pass the entire manual in the prompt.","D":"Train a new LLM from scratch on the technical manuals."},"correct_answer":"B"},
  {"topic":"Topic 1","number":261,"question":"Which phase of the ML lifecycle includes monitoring the model's performance in a production environment, detecting model drift, and retraining the model as needed?","options":{"A":"Data preparation","B":"Model training","C":"Model deployment","D":"Model evaluation"},"correct_answer":"C"},
  {"topic":"Topic 1","number":262,"question":"A company wants to use a foundation model (FM) for text generation. The company needs the generated text to be highly factual and avoid generating low-probability words to maintain accuracy. Which inference parameter should the company adjust to meet this requirement?","options":{"A":"Increase the Temperature.","B":"Decrease the Temperature.","C":"Increase the Maximum output tokens.","D":"Set the Seed."},"correct_answer":"B"},
  {"topic":"Topic 1","number":263,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to store the dense vector representations (embeddings) of its documents to enable semantic search. Which technology is required for storing these vectors efficiently?","options":{"A":"Relational Database Management System (RDBMS)","B":"Key-value store","C":"Vector database","D":"Data warehouse"},"correct_answer":"C"},
  {"topic":"Topic 1","number":264,"question":"A company wants to develop an ML model to predict customer segmentation based on purchasing data without any predefined segments. Which type of learning should the company use?","options":{"A":"Supervised learning","B":"Unsupervised learning","C":"Reinforcement learning","D":"Transfer learning"},"correct_answer":"B"},
  {"topic":"Topic 1","number":265,"question":"A company is developing an ML model for medical diagnosis. The model's predictions must be accompanied by a clear explanation of the factors leading to the decision. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Explainability","C":"Robustness","D":"Accountability"},"correct_answer":"B"},
  {"topic":"Topic 1","number":266,"question":"A company wants to use a large language model (LLM) on Amazon Bedrock to generate code for a new software feature. The company needs to ensure that the generated code is free of known security vulnerabilities. Which solution will reduce this risk?","options":{"A":"Use few-shot prompting with examples of vulnerable code.","B":"Increase the temperature parameter to encourage code diversity.","C":"Use Guardrails for Amazon Bedrock to filter out content related to security exploits.","D":"Decrease the maximum output token length."},"correct_answer":"C"},
  {"topic":"Topic 1","number":267,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to evaluate the model's output for overall quality by having human experts review the responses. Which Amazon Bedrock feature supports this workflow?","options":{"A":"Agents for Amazon Bedrock","B":"Automatic model evaluation","C":"Human-in-the-Loop (HiL) evaluation through Amazon SageMaker Ground Truth","D":"Guardrails for Amazon Bedrock"},"correct_answer":"C"},
  {"topic":"Topic 1","number":268,"question":"A company is developing an ML model to predict the probability of loan default. The model generates a score between 0 and 1. The company needs to use an algorithm suitable for binary classification. Which algorithm meets this requirement?","options":{"A":"Linear regression","B":"Logistic regression","C":"K-means clustering","D":"ARIMA"},"correct_answer":"B"},
  {"topic":"Topic 1","number":269,"question":"A company wants to use a foundation model (FM) for text generation. The company is concerned about prompt injection attacks where a malicious user overrides the system prompt. Which technique is a defense against prompt injection attacks?","options":{"A":"Chain-of-thought prompting","B":"Input sanitization and separation of user and system prompts.","C":"Increasing the temperature parameter.","D":"Decreasing the maximum output token length."},"correct_answer":"B"},
  {"topic":"Topic 1","number":270,"question":"A company is using Amazon Bedrock to build a generative AI application. The company needs to monitor the latency and usage of the foundation models (FMs) in real time. Which AWS service is primarily used for monitoring operational performance and metrics?","options":{"A":"AWS CloudTrail","B":"Amazon S3","C":"Amazon CloudWatch","D":"Amazon Macie"},"correct_answer":"C"},
  {"topic":"Topic 1","number":271,"question":"A company wants to use a large language model (LLM) to perform sentiment analysis on customer reviews, classifying them as 'positive', 'negative', or 'neutral'. Which LLM feature is MOST suitable for this task?","options":{"A":"Text generation","B":"Text classification","C":"Named entity recognition (NER)","D":"Text summarization"},"correct_answer":"B"},
  {"topic":"Topic 1","number":272,"question":"A company is developing an ML model to predict the number of units of a product that will be sold next month. Which type of ML task is this?","options":{"A":"Classification","B":"Regression","C":"Clustering","D":"Anomaly detection"},"correct_answer":"B"},
  {"topic":"Topic 1","number":273,"question":"A company is developing a large language model (LLM) application to write technical articles. The company wants to ensure that the articles are well-structured, logically coherent, and cover all sub-topics in a sequential manner. Which prompting technique is MOST suitable for this task?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Adversarial prompting"},"correct_answer":"C"},
  {"topic":"Topic 1","number":274,"question":"A company is building an AI solution to identify defective parts on a manufacturing line by analyzing images. Which AWS service provides a pre-trained computer vision model for industrial use cases?","options":{"A":"Amazon Transcribe","B":"Amazon Personalize","C":"Amazon Rekognition Custom Labels","D":"Amazon Lookout for Vision"},"correct_answer":"D"},
  {"topic":"Topic 1","number":275,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to deploy a fine-tuned model for production use with guaranteed, reserved capacity for predictable high-volume traffic. Which Amazon Bedrock pricing model meets this requirement?","options":{"A":"On-Demand","B":"Model customization","C":"Provisioned Throughput","D":"Spot Instance"},"correct_answer":"C"},
  {"topic":"Topic 1","number":276,"question":"A company is developing an ML model to predict the likelihood of a power outage. The company must ensure that the model is resilient to data poisoning attacks that could maliciously skew the predictions. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Explainability","C":"Robustness","D":"Transparency"},"correct_answer":"C"},
  {"topic":"Topic 1","number":277,"question":"A company wants to use a foundation model (FM) for text generation. The company wants the output to be concise, to the point, and avoid long, exploratory responses. Which inference parameter should the company decrease to meet this requirement?","options":{"A":"Temperature","B":"Top P","C":"Maximum output tokens","D":"Seed"},"correct_answer":"C"},
  {"topic":"Topic 1","number":278,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to evaluate a custom-tuned model's responses against a reference answer for factual consistency. Which evaluation metric is MOST suitable for this task?","options":{"A":"Perplexity","B":"ROUGE score","C":"BLEU score","D":"BERTScore (or similar semantic similarity score)"},"correct_answer":"D"},
  {"topic":"Topic 1","number":279,"question":"A company wants to use a large language model (LLM) to generate a summary of a text document without providing any examples of how the summary should look. Which prompting technique is this?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Self-consistency prompting"},"correct_answer":"A"},
  {"topic":"Topic 1","number":280,"question":"A company is developing an ML model to cluster its customers into different segments based on a large dataset of customer attributes. Which task is this?","options":{"A":"Supervised classification","B":"Supervised regression","C":"Unsupervised clustering","D":"Reinforcement learning"},"correct_answer":"C"},
  {"topic":"Topic 1","number":281,"question":"A company wants to develop an ML model to predict customer churn. The company wants to use an algorithm that is suitable for binary classification and is known for its high predictive accuracy and robustness. Which algorithm meets these requirements?","options":{"A":"Linear regression","B":"K-means clustering","C":"XGBoost","D":"Apriori algorithm"},"correct_answer":"C"},
  {"topic":"Topic 1","number":282,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to ensure that the application's output adheres to specific brand guidelines, preventing certain topics or tones. Which feature of Amazon Bedrock meets this requirement?","options":{"A":"Agents for Amazon Bedrock","B":"Amazon Bedrock knowledge bases","C":"Guardrails for Amazon Bedrock","D":"Automatic model evaluation"},"correct_answer":"C"},
  {"topic":"Topic 1","number":283,"question":"A company is developing an ML model to predict the probability of a defective item on a manufacturing line. The company is concerned about false negatives (failing to identify a defective item). Which metric is MOST important to optimize in this scenario?","options":{"A":"Precision","B":"Recall","C":"Accuracy","D":"F1 score"},"correct_answer":"B"},
  {"topic":"Topic 1","number":284,"question":"A company wants to use a large language model (LLM) to write a detailed technical procedure. The company needs the LLM to provide a step-by-step reasoning process before generating the final text. Which prompting technique meets this requirement?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Adversarial prompting"},"correct_answer":"C"},
  {"topic":"Topic 1","number":285,"question":"A company wants to build a generative AI solution to help its employees answer customer support questions by referencing an internal knowledge base. The company wants to ensure that the answers are accurate and based only on the internal documents. Which solution meets this requirement?","options":{"A":"Increase the model's temperature parameter to encourage creativity.","B":"Fine-tune the LLM with the internal documents.","C":"Implement Retrieval Augmented Generation (RAG) using the internal documents.","D":"Use zero-shot prompting to minimize context."},"correct_answer":"C"},
  {"topic":"Topic 1","number":286,"question":"A company is developing an ML model to predict the price of a stock at the end of the day. Which type of ML task is this?","options":{"A":"Classification","B":"Regression","C":"Clustering","D":"Anomaly detection"},"correct_answer":"B"},
  {"topic":"Topic 1","number":287,"question":"A company wants to use a large language model (LLM) on Amazon Bedrock to generate creative marketing slogans. The company needs to control the randomness of the output to explore a wide range of creative options. Which inference parameter should the company increase?","options":{"A":"Temperature","B":"Top K","C":"Seed","D":"Maximum output tokens"},"correct_answer":"A"},
  {"topic":"Topic 1","number":288,"question":"A company is using Amazon SageMaker to deploy an ML model for asynchronous inference on large datasets that can tolerate high latency. Which deployment option is MOST cost-effective for this scenario?","options":{"A":"Amazon SageMaker Real-Time Inference","B":"Amazon SageMaker Serverless Inference","C":"Amazon SageMaker Batch Transform","D":"Amazon SageMaker Asynchronous Inference"},"correct_answer":"D"},
  {"topic":"Topic 1","number":289,"question":"A company wants to develop an ML model to group similar customers based on their demographics and purchasing history without knowing the number of groups beforehand. Which algorithm is MOST suitable for this unsupervised learning task?","options":{"A":"Linear regression","B":"K-means clustering","C":"Logistic regression","D":"XGBoost"},"correct_answer":"B"},
  {"topic":"Topic 1","number":290,"question":"A company is developing an ML model for hiring decisions. The company must ensure that the model does not disproportionately favor or disfavor candidates based on protected characteristics like gender or ethnicity. Which principle of responsible AI is the company focusing on?","options":{"A":"Explainability","B":"Fairness","C":"Robustness","D":"Accountability"},"correct_answer":"B"},
  {"topic":"Topic 1","number":291,"question":"A company wants to use a foundation model (FM) for image generation. The company needs to ensure that the generated images are highly realistic and not stylistically abstract. Which technique should the company use to guide the model towards the desired output style?","options":{"A":"Increasing the Temperature parameter.","B":"Adjusting the Classifier-Free Guidance (CFG) scale.","C":"Decreasing the Maximum output tokens.","D":"Setting the Seed parameter."},"correct_answer":"B"},
  {"topic":"Topic 1","number":292,"question":"A company is developing a large language model (LLM) application for a financial institution. The company is concerned about the LLM generating responses that could be interpreted as high-risk investment advice. Which solution will mitigate this risk?","options":{"A":"Increase the temperature parameter to encourage creativity.","B":"Use Guardrails for Amazon Bedrock to filter out content related to financial advice.","C":"Decrease the maximum output token length.","D":"Use few-shot prompting with examples of investment advice."},"correct_answer":"B"},
  {"topic":"Topic 1","number":293,"question":"A company wants to use a large language model (LLM) to classify legal documents into different categories (e.g., 'contract', 'patent', 'memo'). Which LLM feature is MOST suitable for this task?","options":{"A":"Text generation","B":"Text classification","C":"Text summarization","D":"Named entity recognition (NER)"},"correct_answer":"B"},
  {"topic":"Topic 1","number":294,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to evaluate the model's output for helpfulness and relevance to the user's query. Which evaluation approach is MOST suitable for this subjective assessment?","options":{"A":"Bilingual Evaluation Understudy (BLEU) score","B":"Perplexity","C":"Human-in-the-Loop (HiL) evaluation","D":"Mean squared error (MSE)"},"correct_answer":"C"},
  {"topic":"Topic 1","number":295,"question":"A company is building an AI solution to identify key phrases and topics in customer feedback forms. Which AWS service meets this requirement?","options":{"A":"Amazon Textract","B":"Amazon Comprehend","C":"Amazon Rekognition","D":"Amazon Personalize"},"correct_answer":"B"},
  {"topic":"Topic 1","number":296,"question":"A company is developing an ML model to predict customer's next purchase amount (a continuous value). The model's prediction must be close to the actual purchase amount. Which metric is MOST appropriate for evaluating this model?","options":{"A":"Area Under the ROC Curve (AUC)","B":"Mean absolute error (MAE)","C":"F1 score","D":"Perplexity"},"correct_answer":"B"},
  {"topic":"Topic 1","number":297,"question":"A company wants to use a foundation model (FM) for text generation. The company is concerned about the model getting stuck in a loop and repeating the same phrases. Which inference parameter should the company tune to prevent repetitive text?","options":{"A":"Temperature","B":"Top P","C":"Seed","D":"Maximum output tokens"},"correct_answer":"B"},
  {"topic":"Topic 1","number":298,"question":"A company is building a generative AI solution to help its employees draft personalized responses to complex customer inquiries. The company needs the responses to be factually accurate, referencing internal documents, and tailored to the customer's specific issue. Which solution meets these requirements?","options":{"A":"Use zero-shot prompting to minimize context and maximize creativity.","B":"Implement Agents for Amazon Bedrock with a knowledge base and the ability to access customer history.","C":"Increase the model's temperature parameter to encourage diverse output.","D":"Fine-tune the LLM on generic customer service scripts."},"correct_answer":"B"},
  {"topic":"Topic 1","number":299,"question":"A company wants to use a large language model (LLM) to perform translation. The company has a small set of high-quality, domain-specific translation pairs that it wants the LLM to learn from immediately at inference time. Which prompting technique is MOST suitable for this?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Adversarial prompting"},"correct_answer":"B"},
  {"topic":"Topic 1","number":300,"question":"A company is using Amazon SageMaker to deploy an ML model for real-time inference. The company expects a stable, high volume of traffic and requires low, predictable latency. Which Amazon SageMaker deployment feature is MOST suitable?","options":{"A":"Amazon SageMaker Serverless Inference","B":"Amazon SageMaker Real-Time Inference with provisioned instances","C":"Amazon SageMaker Asynchronous Inference","D":"Amazon SageMaker Batch Transform"},"correct_answer":"B"},
  {"topic":"Topic 1","number":301,"question":"A company is developing an ML model for image recognition. The model must perform accurately even when the input images are slightly rotated, scaled, or obscured. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Explainability","C":"Robustness","D":"Transparency"},"correct_answer":"C"},
  {"topic":"Topic 1","number":302,"question":"A company wants to use a large language model (LLM) on Amazon Bedrock to generate code. The company needs the generated code to be deterministic, producing the exact same output for the same prompt to ensure consistency in development. Which inference parameter should the company set to ensure this?","options":{"A":"Temperature to a low value (e.g., 0.1) and set the Seed.","B":"Temperature to a high value (e.g., 0.9) and set the Seed.","C":"Increase the Maximum output tokens.","D":"Increase the Top K value."},"correct_answer":"A"},
  {"topic":"Topic 1","number":303,"question":"A company is building an AI solution to automatically extract key data from scanned invoices, such as vendor name, total amount, and date. Which AWS service meets this requirement?","options":{"A":"Amazon Transcribe","B":"Amazon Comprehend","C":"Amazon Rekognition","D":"Amazon Textract"},"correct_answer":"D"},
  {"topic":"Topic 1","number":304,"question":"A company wants to develop a large language model (LLM) application that summarizes market research reports. The company needs to evaluate the model's output to ensure that the summaries are factually consistent with the original reports. Which evaluation metric is MOST suitable for this task?","options":{"A":"Bilingual Evaluation Understudy (BLEU) score","B":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score","C":"Mean squared error (MSE)","D":"F1 score"},"correct_answer":"B"},
  {"topic":"Topic 1","number":305,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to prevent the model from answering questions about sensitive internal projects. Which feature of Amazon Bedrock should the company use to enforce these content policies?","options":{"A":"Agents for Amazon Bedrock","B":"Amazon Bedrock knowledge bases","C":"Guardrails for Amazon Bedrock","D":"Automatic model evaluation"},"correct_answer":"C"},
  {"topic":"Topic 1","number":306,"question":"A company is developing an ML model for credit risk assessment. The model's predictions must be justifiable, and the contribution of each input feature (e.g., income, debt) to the final decision must be clearly identified. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Robustness","C":"Explainability","D":"Transparency"},"correct_answer":"C"},
  {"topic":"Topic 1","number":307,"question":"A company wants to use a foundation model (FM) to create a chatbot that can book travel arrangements by interacting with external flight booking APIs. Which feature of Amazon Bedrock enables the FM to perform these external actions?","options":{"A":"Prompt engineering","B":"Agents for Amazon Bedrock","C":"Amazon Bedrock knowledge bases","D":"Provisioned Throughput"},"correct_answer":"B"},
  {"topic":"Topic 1","number":308,"question":"A company is developing an ML model to predict whether a customer is likely to purchase a specific product ('yes' or 'no'). Which metric is MOST appropriate for evaluating this binary classification model?","options":{"A":"Mean squared error (MSE)","B":"Area Under the ROC Curve (AUC)","C":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score","D":"Perplexity"},"correct_answer":"B"},
  {"topic":"Topic 1","number":309,"question":"A company wants to use a large language model (LLM) to write product descriptions that are creative and persuasive. The company needs a highly non-deterministic output to ensure diverse marketing campaigns. Which inference parameter should the company increase?","options":{"A":"Temperature","B":"Top K","C":"Seed","D":"Maximum output tokens"},"correct_answer":"A"},
  {"topic":"Topic 1","number":310,"question":"A company is developing an ML model to classify images of different types of wildlife. The company needs to use an algorithm that is suitable for multi-class image classification. Which algorithm meets this requirement?","options":{"A":"Linear regression","B":"K-means clustering","C":"Convolutional neural network (CNN)","D":"Apriori algorithm"},"correct_answer":"C"},
  {"topic":"Topic 1","number":311,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to store the conversational history and model outputs for compliance and auditing purposes. Which AWS service is MOST suitable for long-term, scalable storage of these logs?","options":{"A":"Amazon CloudWatch Logs","B":"Amazon DynamoDB","C":"Amazon S3","D":"Amazon Elastic Block Store (Amazon EBS)"},"correct_answer":"C"},
  {"topic":"Topic 1","number":312,"question":"A company wants to use a foundation model (FM) for image generation. The company needs to ensure that the generated images are distinct and not merely minor variations of a common theme. Which inference parameter should the company increase to promote diversity in the generated images?","options":{"A":"Seed","B":"Temperature","C":"Top P","D":"Maximum output tokens"},"correct_answer":"B"},
  {"topic":"Topic 1","number":313,"question":"A company is developing an ML model to predict customer's annual income (a continuous value). The company needs to evaluate the average magnitude of the errors in the predictions, regardless of direction. Which metric is MOST appropriate for this evaluation?","options":{"A":"Mean absolute error (MAE)","B":"Area Under the ROC Curve (AUC)","C":"Perplexity","D":"F1 score"},"correct_answer":"A"},
  {"topic":"Topic 1","number":314,"question":"A company wants to use a large language model (LLM) to answer complex, multi-faceted customer questions. The company needs the LLM to provide a highly detailed, comprehensive response that leaves no question unanswered. Which solution will MOST likely meet this requirement?","options":{"A":"Decrease the Maximum output tokens.","B":"Use zero-shot prompting with a short query.","C":"Increase the Maximum output tokens and use a detailed prompt.","D":"Set the Temperature to a very low value (e.g., 0.1)."},"correct_answer":"C"},
  {"topic":"Topic 1","number":315,"question":"A company is using Amazon Bedrock to build a generative AI application. The company needs to deploy a custom-tuned model for production and wants a predictable hourly price for guaranteed capacity. Which Amazon Bedrock pricing model meets this requirement?","options":{"A":"On-Demand","B":"Model customization","C":"Provisioned Throughput","D":"Spot Instance"},"correct_answer":"C"},
  {"topic":"Topic 1","number":316,"question":"A company is developing an ML model for a loan approval system. The company notices that the model's performance significantly degrades when it is deployed in a new region with different customer demographics than the training data. Which issue is the model MOST likely experiencing?","options":{"A":"Overfitting","B":"Underfitting","C":"Data drift (or model drift)","D":"Vanishing gradient"},"correct_answer":"C"},
  {"topic":"Topic 1","number":317,"question":"A company wants to develop a large language model (LLM) application that helps its employees write emails. The company needs the LLM to follow a specific, formal email template. Which prompting technique is MOST suitable for this?","options":{"A":"Zero-shot prompting with no template example.","B":"Few-shot prompting with examples of correctly formatted formal emails.","C":"Chain-of-thought prompting for logical reasoning.","D":"Adversarial prompting."},"correct_answer":"B"},
  {"topic":"Topic 1","number":318,"question":"A company is using a large language model (LLM) on Amazon Bedrock to generate summaries of financial reports. The company is concerned about the LLM fabricating facts (hallucination). Which solution will reduce this risk?","options":{"A":"Increase the temperature parameter to encourage creativity.","B":"Implement Retrieval Augmented Generation (RAG) to ground responses in the financial reports.","C":"Decrease the maximum output token length to ensure brief summaries.","D":"Use few-shot prompting with examples of inaccurate summaries."},"correct_answer":"B"},
  {"topic":"Topic 1","number":319,"question":"A company is using Amazon SageMaker to train a model. The company needs to monitor the training job's CPU utilization and loss function in real time to optimize resource usage and detect convergence issues. Which AWS service meets this requirement?","options":{"A":"AWS CloudTrail","B":"Amazon S3","C":"Amazon CloudWatch","D":"Amazon Macie"},"correct_answer":"C"},
  {"topic":"Topic 1","number":320,"question":"A company wants to develop an ML model to predict customer segmentation. The company has a large, unlabeled dataset and wants to discover natural groupings. Which type of learning is MOST appropriate for this task?","options":{"A":"Supervised learning","B":"Unsupervised learning","C":"Reinforcement learning","D":"Transfer learning"},"correct_answer":"B"},
  {"topic":"Topic 1","number":321,"question":"A company is developing an ML model to predict eligibility for a government benefit. The model must provide fair and equitable outcomes, ensuring that no specific demographic group is disproportionately excluded. Which principle of responsible AI is the company focusing on?","options":{"A":"Explainability","B":"Fairness","C":"Robustness","D":"Transparency"},"correct_answer":"B"},
  {"topic":"Topic 1","number":322,"question":"A company wants to develop an ML model to predict if a customer will default on a loan ('default' or 'no default'). Which type of ML task is this?","options":{"A":"Regression","B":"Binary classification","C":"Clustering","D":"Anomaly detection"},"correct_answer":"B"},
  {"topic":"Topic 1","number":323,"question":"A company wants to use a large language model (LLM) to generate new software code based on a natural language description. Which LLM feature is MOST suitable for this task?","options":{"A":"Text summarization","B":"Text classification","C":"Code generation","D":"Named entity recognition (NER)"},"correct_answer":"C"},
  {"topic":"Topic 1","number":324,"question":"A company is using a large language model (LLM) to generate software code. The company needs to evaluate the code's functional correctness (i.e., whether it passes unit tests). Which metric is MOST appropriate for this evaluation?","options":{"A":"Bilingual Evaluation Understudy (BLEU) score","B":"Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score","C":"Perplexity","D":"Pass@k"},"correct_answer":"D"},
  {"topic":"Topic 1","number":325,"question":"A company has deployed an ML model for real-time inference. To maintain high performance over time, the company needs to continuously monitor the change in the distribution of the input data compared to the training data. Which concept is the company monitoring?","options":{"A":"Model convergence","B":"Data drift","C":"Overfitting","D":"Vanishing gradient"},"correct_answer":"B"},
  {"topic":"Topic 1","number":326,"question":"A company is using Amazon Bedrock to build a generative AI application. The company wants to prevent the model from generating content that contains hate speech, harassment, or illegal references. Which feature of Amazon Bedrock meets this requirement?","options":{"A":"Agents for Amazon Bedrock","B":"Amazon Bedrock knowledge bases","C":"Guardrails for Amazon Bedrock","D":"Automatic model evaluation"},"correct_answer":"C"},
  {"topic":"Topic 1","number":327,"question":"A company wants to use a large language model (LLM) to rephrase text in a more professional tone. The company gives the LLM the text to be rephrased and a simple instruction, without any examples of professional rephrasing. Which prompting technique is this?","options":{"A":"Zero-shot prompting","B":"Few-shot prompting","C":"Chain-of-thought prompting","D":"Adversarial prompting"},"correct_answer":"A"},
  {"topic":"Topic 1","number":328,"question":"A company wants to deploy an ML model for real-time inference with guaranteed low latency and the ability to handle a predictable, consistent volume of requests. Which Amazon SageMaker deployment feature is MOST suitable?","options":{"A":"Amazon SageMaker Serverless Inference","B":"Amazon SageMaker Real-Time Inference with provisioned instances","C":"Amazon SageMaker Asynchronous Inference","D":"Amazon SageMaker Batch Transform"},"correct_answer":"B"},
  {"topic":"Topic 1","number":329,"question":"A company is developing an ML model for content recommendation. The company needs to be able to explain to users why a particular piece of content was recommended to them. Which principle of responsible AI is the company focusing on?","options":{"A":"Fairness","B":"Robustness","C":"Explainability","D":"Transparency"},"correct_answer":"C"},
  {"topic":"Topic 1","number":330,"question":"A company wants to use a foundation model (FM) to answer questions based on its private, internal documents without having to fine-tune the model. Which solution will meet this requirement?","options":{"A":"Increase the model's temperature parameter to encourage creativity.","B":"Use zero-shot prompting with a short query.","C":"Implement Retrieval Augmented Generation (RAG) using an Amazon Bedrock knowledge base.","D":"Decrease the maximum output token length."},"correct_answer":"C"},
  {"topic":"Topic 1","number":331,"question":"A company is using a large language model (LLM) for creative writing. The company wants the model to explore less likely, more surprising word choices to enhance creativity. Which inference parameter should the company decrease to achieve this?","options":{"A":"Temperature","B":"Top K","C":"Seed","D":"Maximum output tokens"},"correct_answer":"B"},
  {"topic":"Topic 1","number":332,"question":"A company wants to monitor the usage of its Amazon SageMaker endpoints to identify models that are not used for more than 15 days. Which service will meet these requirements?","options":{"A":"AWS Trusted Advisor","B":"Amazon CloudWatch","C":"AWS CloudTrail","D":"AWS Config"},"correct_answer":"B"},
  {"topic":"Topic 1","number":333,"question":"A company plans to use a generative AI model to provide real-time service quotes to users. Which criteria should the company use to select the correct model for this use case?","options":{"A":"Model size","B":"Training data quality","C":"General-purpose use and high-powered GPU availability","D":"Model latency and optimized inference speed"},"correct_answer":"D"},
  {"topic":"Topic 1","number":334,"question":"An AI practitioner must fine-tune an open source large language model (LLM) for text categorization. The dataset is already prepared. Which solution will meet these requirements with the LEAST operational effort?","options":{"A":"Create a custom model training job in PartyRock on Amazon Bedrock.","B":"Use Amazon SageMaker JumpStart to create a training job.","C":"Use a custom script to run an Amazon SageMaker AI model training job.","D":"Create a Jupyter notebook on an Amazon EC2 instance. Use the notebook to train the model."},"correct_answer":"B"}
];



